https://www.figma.com/
https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RWREfA

Cybersecurity protects your digital information, devices and assets, such as your bank accounts, files, or even photos. System protection is equally important. 
It is a feature that creates restore points that allow you to set your devices to a previously healthier state before changes may have led to malfunctions or data loss. It is your backup plan.

InfoSec - Principle of Information Security - CIA triad - - confidentiality, integraty and availability.
confidentiality: data is kept confidential and private. People not authorized wont see the data. Avoid disclosure
integraty: make sure the data is authentic, accurate, reliable and free tampering. Data is not changed. Avoid alteration
availability: data is available to those who need it. Avoid Denial
Firewall helps avoiding those issues denial, disclosure and alteration

authentication, authorization and accounting (AAA) - framework that controls resources, enforces policies and audit usage.
this helps screening users and keeping track of their activities while they are connected
Authentication - process of identifying and verifying a person or thing.
Authorization - process of controlling access to resources. Privileges to access certain areas
Accounting - tracks information of agent activities on computer devices and networks (time loged in, data sent and received, their IP). Usually is used for audit, analyze user trends, billing.

----------- THREAT LANDSCAPE  

The threat landscape evaluation of every possible and identified threat affecting a particular sector, group of users, time period, and so forth.

Threat landscape analysis makes it possible to see potential information security problems facing a specific entity — a company, an individual, or a whole sector — and to take preventive measures by adopting a proactive approach to information security. 
This can help to identify weaknesses in the environment.

The first step toward implementing effective safeguards is to better understand the types of threats that are out there. 


----------COMMON ATTACKS   https://www.microsoft.com/en-us/security/business/security-101/what-is-a-cyberattack
https://www.microsoft.com/en-us/microsoft-365-life-hacks/writing/how-to-choose-strong-password

TROJAN

Although Trojans behave differently depending on the type, a feature of this common approach is that a user inadvertently introduces malicious code into the organization and triggers it from behind defensive walls. 
The best defense against Trojan attacks is to practice vigilant Internet use. 
Some guidelines are: never click on an unsolicited email with unexpected attachments
always examine domain names and links before clicking on them
Pay particular attention to spelling errors, such as zeros that have been replaced by O's


RANSOMWARE

designed to cause disruption of services. targeting vital infrastructure and services.
Protect against ransomware
Use strong passwords. A strong password is one that is difficult to guess and typically includes a combination of characters, numbers, and symbols.
Keep your system updated with the latest security patches.
Make sure that only people authorized for a system can use it.


BOTNET

They are a means of creating a denial of service for an organization. If a Trojan attack is a subtle attempt to bypass an application's defenses, a bot attack can be described as an all-out climbing of the walls
These requests can come from any Internet of Things (IoT) capable device that has an IP address.
A defensive approach to mitigating these types of attacks is to monitor network traffic for suspicious activity. If a particular source is identified as making repeated calls that affect a system's operations, that address may be blocked.


---------------- OS

The operating system is the software component that interacts with the hardware and software programs to provide users with a standard computer experience. 
three broad categories, which are controlling hardware access, providing a user interface, and managing files and applications.
When interacting with the hardware of a computer, the operating system will communicate instructions through a device driver. These are essentially small pieces of code written by a device manufacturer, 
which allow messages and instructions to be passed between the hardware and other software to control the device.
An application will typically have an application programming interface, more commonly known as an API, which determines a set of rules for interacting with the program. 



------------------ relationship between system fail-safe protection, and server storage and backups

it is good practice to keep duplicates of your information by creating backups that run periodically.

Database servers
assessing storage needs and requirements.
One is durability, good questions to ask when assessing durability is, will it last and what is an acceptable period of time to measure durability?
Another is scalability, does it fit the data needs of the business or does your storage solution adjust accordingly as the business need grows? 
Next, availability concerns how readily available the data is and when it is needed. 
Lastly, consider security, how safe is your data? 

a business can address the problem in two ways. 
The first option is to physically acquire more storage through what is known as direct area storage or DAS. DAS involves additional secondary storage devices that physically connect to the machine accessing it.
The second is to use of Cloud storage.

 four steps protects your data from unexpected shutdowns, technological failure, and malicious cyber activity. 
one replication. This concerns copying data from one location to another. It's like the autosave function in Microsoft Word that keeps recoverable near realtime copies of your information. 
two is snapshots. A data snapshot is a regular save point throughout the day. It's good to implement a policy to schedule automatic saving of all your business information. 
third step involves daily backups. In addition to regular snapshots, it's beneficial to store your information in a second location that is not on your premises (Cloud)
forth step is what is known as the 3-2-1 backup strategy. If the information is particularly important, why not create three snapshots of the data? This is exactly what the 3-2-1 strategy is. 
Use two different formats, such as locally on your computer where you create the information, as well as on your data server. Ideally, one of these copies is kept off site. 
This way, the essential information used to run your business is always protected. Have different levels of importance, so implementing the 3-2-1 backup strategy may be considered excessive. 

 backup storage are durability, scalability, availability, and security.

https://learn.microsoft.com/en-us/sql/relational-databases/linked-servers/linked-servers-database-engine?view=sql-server-ver16
https://learn.microsoft.com/en-us/training/modules/protect-virtual-machines-with-azure-backup/2-azure-backup-features-scenarios



-------------------- environment cloud and on-premises

cloud
pros - lower upfront cost, pay as you need, easier scaling
cons - at risk wider range of threats, constant connection, bound to laws of data storage locations
on-premises
pros - full control hardware, data, software, less vuln to cyberattacks
cons - higher initial cost, less flexible fo scaling

The concept of a firewall applies differently for Cloud environments than it does for on-premises environments.
Whereas an on-premises firewall only needs to monitor external traffic that tries to enter the system, the distinctions are less clear in a Cloud setup in which many system resources may be outside of the system

--------------------- protect the environment

Fundamentally, the steps are the same. Stop unauthorized access, limit mobility within a system once accessed, and employ a backup strategy
Establishing good policies and procedures is vital regardless of how large the lock guard and your door is, it is only useful if the building is secure.
Specifically, a good policy must be able to prevent unauthorized access, limit mobility within a system, and minimize any damage resulting from a breach.

the first step in protecting data is monitoring traffic or incoming traffic is vetted before it can access the system. 
Next managing the endpoints (mobile devices, desktop computers, virtual machines, cloud desktops, servers, and embedded devices, or any specialized devices needed for executing the business needs)
next, identification using Identity and Access Management or IAM. Azure has a dedicated IAM called Active Directory, which ensures that access to specific documentation and services is only given to the appropriate people.
it's not enough to only monitor who gains access. There must also be a means to control what changes they are allowed to perform. 
Finally, one of the strongest measures a company can employ whether on-premises or cloud-based, is to provide technical training for staff. 


Zero Standing Access 
is the overarching concept that access to the production environment must be kept to a minimum and cannot be maintained over time. 
This means that you must validate that you are authorized whenever you wish to access areas related to production. 
Even so, your access will only allow you to make sufficient changes to the area you have been authorized to access.
Zero Standing access is an example of security policy of reducing access

Just-In-Time (JIT)
This means that after accessing a certain area, the user will only maintain access for a limited period of time before being automatically ejected or asked to re-enter an authorization code. 

Just-Enough-Access (JEA)
is about limitations on the changes you can make while you are in the area accessed.

resources and tools used by Microsoft
https://learn.microsoft.com/en-us/windows/security/threat-protection/overview-of-threat-mitigations-in-windows-10

Azure Storage creates and stores multiple copies of data in multiple locations to ensure a solid backup plan
https://learn.microsoft.com/en-us/azure/storage/common/storage-redundancy#geo-redundant-storage


----------------------- Maintanance and Patches

Software updates take an existing piece of code and alter it. 
Motivations for this include adding and improving functionality, addressing and enhancing a security-related element, and removing bugs that affect how a program operates. 

Patches are for newly identified shortcomings or dangers in existing software. They are small pieces of code that only modify the target area without impacting the general function of an application.
The code deployed is never perfect. Over time incompatibilities or issues are identified. 
If the issue is determined to pose an immediate danger to a system then a patch will be issued to address the issue immediately. 
Later, at a scheduled update, a more permanent solution will be deployed. There are two categories of patches. 
First, a bug fix patch is when an issue is identified with the code and the patch temporarily covers it. The second type is a security patch. 
It is when a vulnerability that can be exploited for malicious intent is identified. 
There are also concerns of how an update can make a familiar working environment unfamiliar by changing the layout or removing previously used elements. 
Some patches also add functionality that is not required, and may even degrade the performance of other features. 
Some users become reluctant to accept updates due to poor experiences that change the interface in a way that was undesirable. 


patches are designed to prevent and mediate issues with code. Maintenance is defined as all the changes made to a code after deployment. This includes all the patches and updates. 
A hot patch is an alteration to the code that does not require a system reboot. A cold patch requires the system to be rebooted before the update becomes active. 


Software development is always evolving, and code written today is built on existing code. New software is usually a new variation of code that already exists. 
This means that code written for one purpose is repurposed and used in a later iteration. This can lead to redundant code that potentially acts in different ways than expected.

Bugs are codes that execute unexpectedly and sometimes produce an unintended result. Additionally, security defense and attack measures constantly reveal new vulnerabilities and potential problems with software applications. 
To resolve these issues, the code is continually maintained and updated.

Maintanances measures
predictive - It is the practice of applying maintenance due to a signal that a failure will occur. Signals are determined by analyzing device signature patterns and predicting failure points.
routine - preventative
corrective - necessary repair

The company can choose to accept the vulnerability. This approach means that the company has identified a potential weakness or failure. However, it leaves the problem unresolved.
This may be done because the fix is ​​too large or because the damage that could be done is not great enough to justify the time spent fixing it.


---------------- CVSS

This is a standardized metric used to assess threat levels. However, in some systems, a combination of problems that arise tends to expose the network.
While CVSS can indicate some dangers, the fault in a company's system could be a combination of outdated software coupled with an open port and some other misconfigurations. 
Therefore, the IT professional evaluates each incident on a case-by-case basis. Analysis tools can only give indications; they do not guarantee the security of a system.


Additional resources: Maintenance and patching:
https://learn.microsoft.com/en-us/training/modules/audit-vulnerability-management/attack-simulation-penetration-testing
https://msrc.microsoft.com/update-guide/
https://learn.microsoft.com/en-us/troubleshoot/windows-client/deployment/standard-terminology-software-updates
https://learn.microsoft.com/en-us/windows-server/get-started/hotpatch
https://www.microsoft.com/insidetrack/blog/how-microsoft-is-transforming-its-own-patch-management-with-azure/


---------------- Email

emails are sent using the simple mail transfer protocol and retrieved with the pop three protocol. 
Alternatively, you could use an email client, which is typically an application that you install on your computer. 
A major advantage of an email client is that it allows you to access your existing messages without being online. 
There are many options available, and some of the most popular include Outlook, Gmail, and Thunderbird

Spam refers to unwanted or unsolicited email sent in bulk via text or email. 
Typically, these emails appear as advertisements that attempt to get you to purchase or sign up for a product or website.
But sometimes they ask for more, like trying to get your personal information. 
Even worse, they can be sent as a Trojan horse that encourages you to click on a link that will release malicious code into your system.

https://learn.microsoft.com/en-us/microsoft-365/security/office-365-security/anti-spam-protection-faq?view=o365-worldwide   -> Anti-spam protection FAQ
https://learn.microsoft.com/en-us/microsoft-365/security/office-365-security/email-security-in-microsoft-defender?view=o365-worldwide  ->  Email security with Threat Explorer in Microsoft Defender for Office 365
https://learn.microsoft.com/en-us/microsoft-365/security/office-365-security/investigate-malicious-email-that-was-delivered?view=o365-worldwide


Phishing emails are messages that attempt to hook people into revealing confidential information about themselves. They usually ask the user to click on a link and enter their details into it.
Email spoofing is when a fraudulent email from a known source, such as Amazon or the post office, attempts to trick the user into taking an action, such as completing a payment.
Spear phishing refers to emails created to be from someone you know, with some incentive to click on a link or trigger malware to be installed on the computer.
Whaling is a type of spear phishing attack targeting CEOs or senior executives, with threats of legal ramifications if not responded to.
Advertisements are emails that offer products or services. The offers may be legitimate, but they are often unsolicited and it may take a lot of effort to stop them.
Chain letters: Emails that state that you will have bad luck if you don't forward them to 5 friends. This is a practice that has evolved and is practiced with social media posts.


email providers now offer filtering options that will protect users from spam. 
That includes:
Automatic, continuous virus scanning, which continuously scans content for spam.
Connection filtering monitors the sender profile and only allows in from trusted sources.
Filtering functionality that is based on lists of domains and sites that are allowed or not.
Quarantine is when suspicious messages are labeled as dangerous and kept separate for further investigation.


setup outlook
https://support.microsoft.com/en-us/office/learn-more-about-outlook-59f627d5-d877-4d0b-9e49-484c475a97fc
https://learn.microsoft.com/en-us/training/modules/accessible-content-m365/04-outlook


------------------- Storage

The Azure storage platform includes the following data services. 
Azure Files, which manages file-sharing for Cloud-based storage. 
Azure Blob Storage, which is scalable object store for text and binary data. 
Azure Managed Disks, which involves block-level storage that's accessible using virtual machines. You can have the benefits of versatile storage by integrating Azure Managed Disks into your business setup
Azure allows data access through several methods including HTTP, HTTPS, and rest API. This is the same as accessing a web page by typing the URL in the search bar. 
The difference is that you first need to be authorized to access these sites. This can be useful for remote collaboration, for example, 
say there is a document saved in Azure files that is edited by several employees. They can access the document from various locations, but each employee first needs to login securely to gain access. 


Data is categorized as structured or unstructured data. 

structured data. When you fill out a form, each column has a name and a place to enter the appropriate data, this is an example of structured data. 
Another example is a database table. In every table there are rows and columns and each of the values in the columns relates to the row. 
In databases, information is ordered according to the Schema. The Schema is the template database uses to decide what type of data goes where.

unstructured data, which is less organized with no clear path for searching or filtering. 
Imagine taking your favorite book, separating each page, then placing the individual pages into a box and shaking it. All the information is still there, but there was no structure in how it is saved. 
You may have come across the term blobs. Blob is an acronym that stands for binary large objects, and it simply stores unstructured data. As the name suggests, it stores large, unstructured objects. 
Examples of unstructured data that accompany may keep include streaming data from the security cameras or sensor output data from on-premises devices.

Blob works
Blobs are stored in containers. This is like a filing system where each container has a general name like pictures or movies. Inside this container, you can store as many blogs as required.
The blobs themselves will be unstructured, and further filtering or searching methods are needed to find a specific item inside the blob.


--------- data lake   https://azure.microsoft.com/en-us/products/data-lake-analytics/

A repository that stores large amounts of data for later processing is known as a data lake. A data lake allows actionable insights to be extracted from the data at a later stage, like reports, big data, analysis


Data Lake Benefits and Challenges

Data lakes are widely used and maintained by companies, but why is this the case? Some of the reasons may include:

The data may be more valuable in the future in ways that are not currently known.
By storing the data wholesale, scientists can make different exploratory queries with the aim of discerning some valuable insights. These potential insights can be lost if data is processed before it is stored.
The unstructured nature of a data lake means that data can be stored in a variety of ways and does not need to be processed and transformed beforehand.

In addition to their benefits, data lakes also present some challenges, such as the following:

The lack of a schema means that data does not need to be processed before being stored. However, this makes it difficult to query and find specific data.
A lack of data analysis means there is no way to ensure that the data stored has merit or value.
Security can be an additional challenge, as lack of knowledge about the quality of stored data makes it more difficult to regulate access.
The lack of structure to data means that some information can be lost or forgotten over time.


------- data warehousing

A data warehouse is like a data lake, except that the information found in it has been processed and cleaned so that it is easily acceptable. 
To do this, lake data is extracted, formatted, validated, summarized, and otherwise processed and stored in the data warehouse. When the data is in the data warehouse, 
it is possible to obtain actionable intelligence from it.


Data warehouse benefits and challenges

A company may choose a data warehouse over a data lake for the following reasons:

It serves as a single source of truth as past performance can be compared with current performance. For example, if a company implements a new format for maintaining records, it can reference historical record storage to prove the effectiveness of the new approach.
A data warehouse enables the filtering and cleaning of data in a data lake and facilitates analysis to obtain essential, actionable insights.
Data warehouses store information in a structured way. This makes it much easier to apply learning models to data without having to change the way the data is presented.
A data warehouse leads to greater awareness of data and allows for a better verification process for proper access.

However, remember that data warehouses do not come without some disadvantages, such as the following:

Creating a data warehouse from a data lake requires significant effort. It can be challenging to know how data is structured without in-depth investigation. For example, images or words may need to be converted to numbers for analysis, but formatting data for one purpose may be inappropriate for another.
Domain expertise is required to orchestrate the data. Due to the potential size of data lakes, data transfer and processing can be expensive. Therefore, before applying any process, a domain expert must identify what and how data should be transferred.
Cleaning data into a desirable format can be challenging when there are many data items.


Three useful Azure technologies that can be used for data storage are:

Azure SQL Database: A fully managed cloud relational database that offers automatic remediation, built-in security, and on-demand data protection.
Azure Synapse Analytics: A service that optimizes analytics tasks to provide faster insights. It provides integration between Microsoft's data warehousing and big data analytics capabilities in a single service.
Apache Hive: Data warehouse software built on top of Hadoop (a framework for online distributed databases) to provide data summarization, querying, and analysis.


---------------- Machine Learning

It is possible to automate much of the analysis by training a computer to do it instead through a process called machine learning. 
Machine learning is a part of artificial intelligence that helps machines learn from data and make predictions. 
It's a way of teaching a computer to recognize patterns and make decisions based on what it has learned. 
can teach the computer how to find patterns in whatever you want, for example, sales data using a set of rules called algorithms. This helps the computer to better understand the data.

it can be applied to cybersecurity as well, so how would that work?
Imagine you are a security specialist and you want to prevent unauthorized entry into a system, you might set up a rule that too many failed login attempts will lock in account for awhile. 
Or you might note the location and prevent access if it is different from what is expected.

You may want to create a system to monitor credit card transactions for fraudulent activity. To reduce illegal activity, sophisticated machine learning models are trained to identify anomalies in a customer's action. 
To train a learning model for this, a representation of your daily activities is built. 
When processing images, these data points can be represented by pixels. In this case, the same algorithm may instead receive different data points, such as:

The frequency of the activity.
The location from where a transaction was executed.
The amounts spent.
The types of purchases made.

When a flag is raised, it can trigger another action, such as sending an alert notification or activating an authentication application that needs to be released before the action is sanctioned. 
The training data for these models is created based on previous transactions and instances labeled as "standard" and fraudulent. 
First, the algorithm will identify anomalous activity or activity that deviates from the pattern. This can be used to apply additional checks to determine whether fraudulent behavior is occurring. 
Furthermore, this methodology can be applied to detect attack patterns. Company logs after a breach can be analyzed to identify any patterns of activity that indicate an attack is in progress or about to happen. 
These are called signature patterns.

Machine learning engineers have created smart solutions that can catch the small giveaway details that people often miss. This leads to more capable cybersecurity systems that demand less human vigilance.
By analyzing a senders emails a machine can learn to distinguish the tiny differences that separate a fake email from the real thing.

Why is it important to preprocess data before using it to train a machine learning model? 
if the data contains errors, the computer will give poor or inaccurate predicitions


================== NETWORKING ========================

A network is a group of connected devices that can communicate with one another and share resources.
WANs cover vast areas like a city or even a whole country. The Internet is an example of a wide area network.
metropolitan area network, or MAN. A MAN is used to connect local area networks located in different buildings or neighborhoods within a city. It is mostly used by organizations that have multiple locations within a city. 
SAN, which is used to provide multiple servers access to storage devices such as hard drives. 


These include bus, ring, star, mesh, entry topologies.
A network topology determines how devices are connected and data travels through the network.

Bus topology is best for small networks with few devices that are located close together.
All devices on the network receive the data, but only the device that the data is intended for processes it. 

ring topology, which connects devices in a loop or circle. Data is sent from one device to another in a specific order, and each device repeats the data before passing it on to the next device. 
In a ring topology, data travels in only one direction and the devices are linked to each other through connectors. 
Ring topology is usually used for high-speed data transfers between devices in a closed loop network when the data needs to travel in a specific direction from one device to another. 

star topology, devices are connected to a central switch. The switch acts as a central control point for the network and all data is sent through it. 
In a star topology, each device is connected to the switch with its own cable. This is the most common topology used in homes or small offices
is simple and it provides and maintains good performance. It's also very simple to troubleshoot because it's easy to isolate and investigate one device without affecting others

mesh topology, in which devices are connected to each other in a network of interlocking nodes. An interlocking node is when a device is connected to two or more devices in a mesh network. 
In such an arrangement, data can be sent from one device to another through multiple paths and there is no central point of control. 
Mesh topology is a good choice when the reliability is important because if one path fails, data can be sent through another path.

tree topology. In this case, devices are connected to a central bus or line, and then sub-networks are created with their own bus or line. Each sub-network can then have its own tree topology. 
Tree topology is also known as hierarchical topology. It is used for medium to large size networks where multiple star topologies need to be connected to each other. 


A   10.0.0.0-10.255.255.255
B   172.16.0.0 - 172.31.255.255
C   192.168.0.0 - 192.168.255.255

By default, Windows uses APIPA to assign itself an IP address automatically from the 169.254.0.0 to 169.254.255.255 address range.

https://learn.microsoft.com/en-us/training/modules/network-fundamentals/5-ip-tcp-basics
https://learn.microsoft.com/en-us/dotnet/fundamentals/networking/ipv6-overview
https://learn.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd379516(v=ws.10)


Hybrid networks come in many different shapes and sizes. But it's the mix of connectivity types that makes them hybrid. 

What is cloud?
1 - On-Demand Self-Service - can provision capabilities as needed without requiring human interaction.
2 - Broad Network Access - access services over the network and accessed through mobile phones, tablets, laptops, and workstations.
3 - Resource Pooling - no control or knowledge over the exact location of the resources, those resources are pooled to serve multiple consumers.
4 - Rapid Elasticity - capabilities can be elastically provisioned and released to scale rapidly in response to system load
5 - Measured Service - Resource usage can be monitored, controlled, reported and billed. Pay for what you consume


--------- OSI model

The first advantage of the OSI model is that it provides an organized structure by dividing the functions of a network into seven transparent layers. 
This makes it easier for network administrators and engineers to understand the flow of data and troubleshoot problems.

OSI model is also widely accepted and standardized. This simplifies communication and collaboration between different networks and vendors.

Each layer in the OSI model can be modified or improved independently without affecting the other layers. 

The bottom layer, or the physical layer, converts the data into wireless or electrical signals for transmission through the air or through cables.
The next layer, the data link layer, ensures that the data is ready for transmission by making sure it is reliable and error free. 
The network layer selects the best path to route data packets over a network and addresses devices with the IPv4 and IPv6 protocols. 
Then the transport layer establishes connections between devices and can ensure reliable transport between the two. 
The fifth layer, the session layer, is responsible for managing communication sessions or states between applications. 
Next up, the presentation layer's role is quite interesting since it deals with data formatting, encryption, decryption, and data presentation. 
And the final layer, or the application layer, plays an essential role by enabling the users or devices to communicate with each other. 
This layer provides an interface with which you can access the network to perform the necessary tasks.


smtp, http protocol - application layer (TCP/IP SUITE)
TCP, UDP protocol - transport layer (TCP/IP SUITE)
IPv4, IPv6 protocol - internet layer (TCP/IP SUITE)
Ethernet, WiFi protocol - network access layer (TCP/IP SUITE)


-------- TCP/IP

TCP/IP is the primary protocol used all over the world by millions of devices to send information online on different kinds of networks. 

The Internet Protocol or IP ensures the packets get to the right destination and the Transmission Control Protocol or TCP makes sure that the packets arrive safely and in the correct order. 
even if some packages get lost along the way, TCP will send them again to make sure the information gets to its destination intact.

First, data is divided into smaller parts called packets, before being sent over the network. These packets then travel over the network, which may be physical wires or wireless signals to reach their destination. 
The next step is the reception of the packets. The destination device collects all the packets and puts them back together to recreate the original data. But sometimes data can get lost along its journey. 
So the fourth step is to make sure all the packets are correct and have arrived in the right order. 
For this reason, the TCP protocol adds extra information to each segment of data known as a sequence number and acknowledgment number. 
When delivered successfully, an acknowledgment will be sent back to close the process. 
But the TCP delivery check process can only happen once devices have found each other over the network, and this happens next with the IP protocol
The bottom layer is the network interface or data link layer and is physical link between the computer and the network. 
It is responsible for sending and receiving data over the network using hardware such as network adapters. The next layer, the Internet layer, forwards packets from the source to the destination.
The transport layer works in the background and ensures that the data is sent reliably, meaning all data packets are verified by the TCP protocol, but this takes time.
The top layer, the application layer deals with the applications running on the devices and the data that they generate. In other words, it provides an interface for the user to access network resources. 


A camada de transporte é responsável pela entrega de dados entre aplicativos em hosts separados.
A camada da Internet é responsável por endereçar e rotear pacotes de dados entre redes

 IP addresses are vital in identifying different devices on a network to route traffic to the intended destination.

ports, and they allow various types of data to be sent and received by specific applications.
ports identify and allow certain types of data to access the network. 
if data tries to enter a network without the proper port number, the network's security measures, like firewalls, may block its entry to protect against unauthorized access.
Port numbers are used to identify different types of data during transmission and are assigned within the transport layer of both the TCP IP suite and the OSI model.

Firewalls rely on port numbers to permit or deny access to a network, but managing the range of port numbers is equally important to prevent unauthorized access. 

Port numbers identify a particular application or service on a system. An IP address identifies a machine in an IP network and determines the destination of a data packet, 
while port numbers identify particular applications or services on a system.

The sender selects a source and destination IP address and identifies the protocol they want to use, which is SMTP. SMTP uses port number 25 for its communication.
The destination port is always the service or protocol being accessed. Once the protocol is chosen, the devices involved have a set of rules to follow to ensure the conversation is successful.

By using a separate port number for each session, multiple sessions can be opened simultaneously on the computer

https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml

Identifying Protocols and Sessions on a Windows Machine
 netstat -a

https://blog.hubspot.com/website/http-vs-https   
The SSL certificate encrypts your information 
The TLS Protocol prevents your data transfer from being tampered with, ensuring users communicate with the right website 


----- DNS 
https://learn.microsoft.com/en-us/windows-server/networking/dns/quickstart-install-configure-dns-server?tabs=powershell
https://public-dns.info/


The DNS server acts as a translator, taking the name you typed and converting it to an IP address that can be located for the relevant website. 
The IP address is stored in the DNS server as a record and there are a number of record types. The DNS server will use an address record or a record when simply looking for a website name translation. 
Another type of record is a domain name system service record, or SRP, which can tell the device what services are available for a particular website
DNS needs to be fast. UDP is the preferred protocol because it doesn't provide packet delivery check overheads. 


common attacks on DNS

DNS Flood Attack
DNS Amplification
DNS Tunneling
DNS hijacking
DNS spoofing


Monitoring can be divided into two main tasks: network monitoring and network traffic monitoring. On the one hand, network monitoring involves monitoring network devices for availability and failures. 
On the other hand, network traffic monitoring is about monitoring what protocols and data are circulating on a network and monitoring performance and security threats.

Bandwidth monitoring
Bandwidth  determines the rate of data movement on a network.
Bandwidth is like the road, you can only accommodate so many cars before the road becomes blocked. That's why it's critical to monitor what's using a lot of bandwidth.

User monitoring
When monitoring the network, you also want to track users to see what applications they use and what their regular daily activities are. This can create an audit trail, but more importantly, 
it reveals patterns so you can better understand how network traffic behaves on a day-to-day basis. Knowing how the network behaves makes it easier to identify when something is not right.

Network traffic monitoring steps
Network monitoring can be divided into three steps: 
Step 1 is choosing the right data source. 
Step 2 involves analyzing the correct component in a network. 
Step 3 is using a monitoring tool to optimize and display the data in a readable format.

Step 1: Choosing data source and protocols
To monitor network traffic, you need to determine the best source. This monitoring can be divided into two categories: packet capture and flow analysis.

Packet capture
This is a way of collecting copies of packets that are moving across a network. You may decide to do this at different points on the network using a computer running packet capture software and a mirrored port.
A mirrored port is created to copy all data passing through it to the port on your computer and to the connected packet capture software. 
Traditionally, an application called Wireshark has been the best option for carrying out this activity.

Flow Analysis
Flow analysis is supported by many network devices and is typically a built-in feature. Two protocols that can do this are called Netflow and Sflow.
Netflow is a Cisco proprietary protocol that runs on Cisco routers and switches. Sflow is designed to work across platforms.
Netflow only collects IP traffic, but SFlow can collect and analyze data from layers 2 to 7 of the OSI model. 
This type of analysis does not copy data from one port to another, so it is very flexible as data can be collected centrally.

Step 2: Selecting the Correct Component
Devices on the network that can support traffic monitoring include servers, switches, routers, and firewalls. You can even monitor specific interfaces and their applications, in addition to devices.
However, you do not want to capture everything that happens everywhere on the network, as this will generate a lot of data for analysis. You need to choose the main areas of the network that oversee communication.

But as the network grows, packet capture will only be used to troubleshoot specific problems in a specific area, as it is restricted to the area you are connected to. 
Flow analysis does not capture entire data packets like packet capture. 
Instead, it captures packet details such as ports and IP addresses. In other words, just the information needed to understand data from many different devices at the same time.

Step 3: Use monitoring tools
When a network grows, so does the amount of data flow that you will need to analyze, and this is when you need third-party software that can collect all flow traffic. 
There are many different traffic monitoring tools that are very capable of analyzing flows and putting the data into an easy-to-read format. 
Typically, they also include tools to alert a network manager about problems or anomalies in the network.



Health analytics and metrics

Health and metric analysis are about spotting trends and patterns in data collected from network traffic monitoring. 
The identified trends and patterns can then be used to proactively introduce traffic management methods to keep the network healthy. 
Traffic management methods can ensure that the capacities on network devices are maximized without overloading them thereby increasing the return on investment or ROI. 
Metric analysis involves measuring key performance statistics to understand how something is performing and predict its future performance based on the gathered data. 
Tools used for this prediction generally need at least 30 days worth of data to create a baseline performance. 
For a network, there are several different metrics that can help determine network health and performance. 


First is bandwidth usage. 
This metric is about checking that you are not going over the amount of available bandwidth. 
If the bandwidth usage is too high, it can affect the network's performance by slowing things down.
The second metric is packet loss. 
When packets get lost on the network between the source and destination, you know that TCP can re-send those lost packets. 
But that can actually create more congestion on the network if it occurs too often. 
The third is latency. 
This is how long a packet takes to move across the network and back again. It's also known as the round trip time or RTT. 
Last is network availability. 
This is a key metric because it reflects up time on the network. In other words, it tells you when the network is working and when it is not. 
These metrics and others can tell you how healthy your network is and how well it's performing.

traffic management. A network can be set up to manage its performance by utilizing something called Quality of Service or QoS. 
QoS is a suite of different traffic management mechanisms that can be used at different times based on network performance. 
Although traffic monitoring is ongoing, traffic management mechanisms should only be turned on when needed. 
If everything works as it should, you don't need to create extra work. Two of the mechanisms included in QoS are traffic marking and prioritization.

https://www.fortinet.com/resources/cyberglossary/qos-quality-of-service

For example, real-time information like video calls should be prioritized. Less critical traffic, like email can be given a low priority.


this information should not only be monitored; they must also be registered. -> log file

Typically, logs contain five header areas. Are they:

Timestamp - the time of the event.
Record level - the degree of severity or importance of the event.
Username - who caused the event.
Service or application - what caused the event.
Event description - what happened.


Types of log files

Event Log - Records information about network traffic usage and tracks login attempts, application events, and failed password attempts.
System log (or syslog) - records operating system events, including startup messages, system changes, shutdowns, errors, and warnings.
Server Log - Contains a record of activity in a text document related to a specific server over a specific period of time.
Change Log - Lists changes made to an application or file.
Availability Log - Tracks system uptime, availability, and performance.
Authorization and access log - lists who is accessing applications or files.
Resource log - Provides information about connectivity issues and any capacity issues.

Logs can be stored in several different formats. Applications like Windows Event Viewer make it easy to troubleshoot and view different events. 
But not all devices on a network have a graphical application like the event viewer on a Windows PC. Many logs are plain text files

have a tool that can capture, display and even analyze the logs for you. For example, Windows Azure Monitor

findstr is the command to use in the command prompt application. Linux uses grep command
Windows PowerShell is another powerful tool used to filter and search using the Select-String command. https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/select-string?view=powershell-7.3


remote access also poses some cybersecurity risks. 
First, remote access software is a prime target. When remote access software is unsecured, outdated or unpatched, it can allow unrestricted network access to anyone on the internet.
Weak authentication, like simple passwords, can allow cybercriminals to take over user accounts. 
criminals can also exploit remote users by sending fake remote access links or malicious attachments in phishing emails.

VPNs are widely used for remote access to corporate networks because they provide an improved level of security. VPNs use many different protocols for authentication, data encryption, and tunneling.
Tunneling is a process by which VPN software connects to the destination and sends data. Some of the protocols VPNs use include IPSec, SSL or TLS, PPTP, L2TP, and OpenVPN and others. 
VPNs provide a secure and private connection between two devices over the Internet. VPNs use encryption and authentication for your Internet traffic,
making it difficult for third parties to intercept or eavesdrop on your traffic.

RDP is built into the Windows operating systems and is commonly used for remote access to individual computers or servers. 

But what if you need to connect over an unsecured network like free public WiFi? Well, in unsecured networks, IT technicians use the Secure Shell

Remote Access Services, or RAS, a Microsoft technology that allows dialing into a network from a remote location. 
It allows remote users to establish a secure connection to the network over a phone line or the internet. 
RAS is a predecessor of Routing and Remote Access Service, or RRAS. This built-in Windows operating system tool enables remote access and routing services. 
It can be used to create a VPN server as well as dial up, and wireless networking connections. RRAS also supports several authentication methods. 

How does DHCP work?
When a device connects to a network, it sends an IP address request to the DHCP server. 
The DHCP server then assigns an available IP address to the device, along with other network configuration settings such as
Subnet mask
Default gateway
DNS server addresses

DHCP uses a process called leasing to specify IP addresses. When a device needs IP addresses and sends a request to the DHC server, 
the server assigns it an address from the pool of available IP addresses. Additionally, the server assigns a lease time to the IP address, 
which is the length of time that the device can use the IP address before it needs to be renewed.
When the lease time expires, the device must renew the IP address by requesting a new lease from the DHCP server. 
If the IP address is still available, the server will renew the lease and extend the lease term. If the IP address is no longer available, 
the server assigns the device a new IP address.

https://learn.microsoft.com/en-us/troubleshoot/windows-client/networking/set-up-your-small-business-network
https://learn.microsoft.com/en-us/troubleshoot/windows-server/printing/install-configure-file-print-server
https://learn.microsoft.com/en-us/training/modules/deploy-manage-dynamic-host-configuration-protocol/
https://learn.microsoft.com/en-us/windows-server/networking/technologies/dhcp/dhcp-deploy-wps
https://learn.microsoft.com/en-us/training/modules/explore-remote-access/



One way to improve the security of passwordless authentication is by incorporating a two-factor authentication system.

authentication protocols that organizations use, such as LDAP, which stands for Lightweight Directory Access Protocol.
LDAP is a protocol used to access and manage centralized user authentication and authorization. 
Azure Active Directory is a very popular service that uses LDAP, or RADIUS, which stands for Remote Authentication Dial-in User Service. 
RADIUS is a client-server protocol that provides centralized authentication, authorization, and accounting management for users who connect and use a network service. 
It is often used for remote access to networks. 
Terminal Access Controller Access Control System Plus (TACACS+). This is a security protocol that provides centralized authentication, authorization, and accounting services. 
TACACS+ separates authentication, authorization and accounting functions, allowing for more granular control of access to network resources.

Another protocol is called certificate-based authentication, which is an authentication method that uses digital certificates to verify the identity of a user, device, or application.
And lastly, Kerberos is a network authentication protocol that provides mutual authentication between a client and a server in a network environment. 
It protects businesses against password sniffing attacks by encrypting authentication credentials. It is commonly used in Windows domains.


Authorization templates

Role-based access control (RBAC): RBAC is a model that assigns permissions and privileges to users based on their predefined roles in an organization. 
This model is designed to simplify the management of large-scale systems by reducing the need for individual user-level permissions. 
This is the most common and widely adopted access control model. With RBAC, you can easily form a group of individuals, assign them to a role, and then grant or deny permissions based on that role.



Wi-Fi router security protocols

WEP (Wired Equivalent Privacy): WEP is an older wireless security protocol that is no longer considered secure. WEP uses a shared key to authenticate users and encrypt data. 
However, WEP is vulnerable to security breaches and its encryption can be easily broken.

WPA (Wi-Fi Protected Access): WPA is a wireless security protocol that offers stronger encryption and authentication than the older WEP standard. WPA uses a passphrase or key to authenticate users and encrypt data. 
WPA2 is the latest version of WPA and is considered the most secure wireless security protocol.

WPA2 (Wi-Fi Protected Access II): WPA2 is the most widely supported wireless security protocol today. 
It uses a stronger encryption algorithm than WPA and offers better protection against hackers and security breaches.

WPA2-PSK (Wi-Fi Protected Access II with Pre-Shared Key): WPA2-PSK is a version of WPA2 that uses a pre-shared key (PSK) for authentication. 
This means that all devices that connect to the wireless network must know the same PSK to access the network.

EAP-TLS (Extensible Authentication Protocol-Transport Layer Security): EAP-TLS is a wireless security protocol widely used in enterprise-grade networks. 
It offers robust security using digital certificates to authenticate users and encrypt data. EAP-TLS is considered one of the most secure wireless security protocols available.

MAC-based security: MAC-based security is a wireless security protocol that uses a device's Media Access Control (MAC) address to authenticate users and grant access to the wireless network. 
MAC-based security is more secure than WEP, but less secure than WPA or WPA2.

How to keep a wireless network secure
Remember to change the default username and password
Always use strong encryption: It is essential to enable WPA2 (Wi-Fi Protected Access II) encryption on your router to secure your wireless network.
Set up a guest network: If you frequently have visitors who need to use Wi-Fi, set up a guest network with a different password to keep the main network secure.
Enable MAC address filtering: MAC address filtering allows you to restrict access to your network by only allowing specific devices with pre-approved MAC addresses to connect.
Keep your router's firmware up to date: Router manufacturers regularly release firmware updates to address security vulnerabilities. Make sure to keep your router's firmware up to date by regularly checking for updates.
Disable remote management: Unless you need it, disable remote management on your router. It is a security risk as it allows cybercriminals to access router settings from outside your network.


The basics of modern authentication - Microsoft identity platform
https://www.youtube.com/watch?v=tkQJSHFsduY

https://www.microsoft.com/en-us/security/business/solutions/passwordless-authentication

https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/vpn/vpn-connection-type


DDoS is one of many kinds of cybersecurity attacks, and it involves multiple sources simultaneously flooding a network with traffic, making it impossible to operate. 

A network attack is mostly an attempt to gain unauthorized access to a computer network, system, or device with the intent of stealing, damaging, or manipulating data.

Active attacks are usually easier to detect than passive attacks because they typically involve some level of disruption to network operations, such as modifying or stealing data.

Sniffing is part of espionage and involves listening to communication between two devices, intercepting it, capturing it and analyzing it. 
This type of attack can steal your data remotely, without even physically accessing your computer.
The sniffing software simply sits in between the communication process, sees what's coming in and out, and reads it all.

Spoofing is done using specialized software or tools to modify packet headers, forge DNS responses, or create ARP packets. 
This allows attackers to intercept or redirect network traffic, bypass security controls, or gain unauthorized access to sensitive systems and data. 
In IP spoofing, for example, the attacker changes the source IP address in the IP packet header, making it appear as if the packet originates from a legitimate source. 
In DNS spoofing, the attacker provides a forged DNS response, directing the user to a malicious website. 
The main objective of spoofing is to deceive network components or users, allowing the attacker to carry out various malicious activities while disguising himself as a trusted entity. 
Tools like hping, scapy or Nmap are used to carry out spoofing attacks.

----- Network attacks

eavesdropping, which involves intercepting and reading data transmitted over a network. 
This can include sensitive information such as passwords, credit card numbers, and other personal data. Eavesdropping involves various tools and could be an automatic or manual process. These tools are used for intercepting, capturing, and analyzing network traffic.
This process is called packet sniffing. The impact of eavesdropping can be severe as it can lead to data exposure and information theft.

 Packet spoofing is when an attacker sends packets of data with a forged source address to make it appear that the packets are coming from a trusted source. 
The purpose of packet spoofing is often to trick the recipient into accepting the packets as legitimate and allowing the attacker to gain unauthorized access to the recipient's network or systems. 

 IP Spoofing. And it involves forging the source IP address of a network packet to make it appear as though it came from a trusted source. This can be used to gain unauthorized access to a network or to steal data.
To prevent Spoofing, it is essential to implement network filters to prevent Spoofed packets from entering the network.

 man-in-the-middle attack involves intercepting communication between two parties and relaying messages between them. 
This gives the appearance of normal communication while secretly eavesdropping and potentially modifying the messages. This can lead to information theft, data exposure, and unauthorized access.

---- malicious common attacks

Another malicious attack type is Backdoors, and just like the name suggests, it involves creating a hidden entry point into a network or system that bypasses standard security measures. 
Backdoors can be used to gain unauthorized access, steal data, or install malware.

password cracking, which involves attempting to guess or crack a user's password to gain access to their account. 
This can affect not only users, but also servers, Wi-Fi routers, or any network resource that is protected with a password. 

SQL injection. SQL, or Structured Query Language, is a language used to access and alter database tables and records, and SQL injection is one of the most common attacks against web applications. 
It causes significant damage to organizations and businesses that use databases to store sensitive data. 
With SQL injection, attackers can exploit vulnerabilities in SQL statements to access sensitive information such as usernames and passwords and use this information for further attacks. 


---- Cracking Wi-Fi passwords 

Dictionary attack: The attacker uses a list of commonly used passwords or phrases to attempt to systematically gain access to the network.

Brute force attack: The attacker systematically tries all possible combinations of characters to discover the password. This method can be time-consuming and resource-intensive.

Rainbow Table Attack: The attacker uses precomputed tables of hashed password combinations (called rainbow tables) to quickly look up the plaintext password corresponding to a given hash. 
This method can be faster than brute force, but it requires significant storage resources. A password hash is a mathematically calculated, encrypted version of your password.

suspicious signs of a phishing attack. 
These signs include:
First-time or infrequent senders
Incompatible email domains
Generic greetings
Urgent calls for action or threats
Inadequate spelling and grammar
Suspicious links or unexpected attachments


-------- Network security

Effective network security is built upon three core principles. 
Confidentiality, integrity, and availability. 
Confidentiality ensures that only authorized individuals have access to sensitive information. 
Integrity guarantees that your data remains accurate and unaltered. 
Availability ensures that your digital resources are accessible to authorized users whenever needed. 

network security tools, 
Firewalls are the first line of defense for all networks and a critical tool in the network security toolbox. 
firewalls prevent suspicious traffic from coming in or going out of the network. But they also stopped port scanning. 
Another crucial tool is passwords, which is not just for protecting user accounts, but also to secure servers, Wi-Fi networks, and other network devices.
should also implement passwordless authentication and multi-factor authentication where possible, for an extra layer of security
An Intrusion Detection System or IDS, is another preventative tool. It continuously monitors networks for any signs of suspicious activity or potential threats.
An IDS analyzes network traffic patterns and compares them against known attack signatures
Anti-malware tools also form a part of the network security toolbox.
network administrators should perform regular network maintenance tasks which can protect against various types of attacks. 
Network administrators should regularly update software, perform vulnerability assessments, and monitor traffic and system logs. 
Finally, it's crucial to educate the users in your network because human error is often considered the main weak link in a network


---- firewall    https://www.checkpoint.com/cyber-hub/network-security/what-is-firewall/
 
a firewall is a network security device that sits between a trusted and untrusted network, such as the Internet.
You can compare it to a country's border control. In the same way, officials check people to ensure they aren't carrying anything that 
isn't allowed in and out of the country, firewalls analyze all incoming and outgoing traffic. 

By default, most firewalls deny all incoming traffic and filter outgoing traffic until an organization security team configures what traffic should be allowed in and out. 
The firewall checks each data packet to determine if certain conditions are met before it allows traffic to pass through. These conditions could be; 
a specified IP address, a network port, a network protocol or a combination of conditions.

Some firewalls are hardware-based and are inside devices built to act as firewalls. Firewalls can also be virtualized to run on a server.
Other firewalls are software programs that run on personal computers or even inside routers

Firewalls have to check every packet of data that arrives against a list of rules to decide if the packet is permitted or denied. 
This can be very time-consuming and counterproductive, slowing the network down. When it comes to a network and its firewall, some decisions need to be made.
One, what traffic needs to be checked and two, where does it need to be checked? In other words, where's the best place to put border controls in a network? 
Security teams make these decisions by assessing the risk that different network devices or zones carry. A zone is made up of a single device or devices with the same trust level. 
These devices can be physically remote from one another on the network or they can be close by. But as long as they all share the same trust level, they're in the same zone. 
The trust level is assigned on a scale of 0-100. The higher the number, the higher the level of trust and the firewall acts according to what zone traffic is going to or coming from. 

Here's an example of a network with three zones; private, public, and perimeter, which are very typical for many networks today. 
A trusted or private zone has resources and devices that should never be accessible to anyone outside of an organization.
A firewall will block all incoming traffic. Examples include printers, workstations used by internal users and internal servers. These are typically assigned the highest trust value of 100. 
Zones with a high number require more protection than others. But it also means that the firewall won't check outgoing traffic as rigorously as for other zones. 
The perimeter zone, also known as DMZ or demilitarized zone, is where resources and services accessible from outside the organization are available. 
For example, you can use a perimeter network to provide access to an application, a partnering organization or a supplier. 
This zone is typically assigned the value of 50. Not all incoming traffic will need to be checked, but it's still treated with a lot of caution. A public zone contains everything outside the organization. 
This zone is part of the internet or another network and is not under the organization's control. It carries the most risk. It has a trust level of zero. In other words, everything coming in needs to be checked. 
Dividing a network up into these three different zones helps security teams to know which part of the network requires the most protection and where traffic should be checked most rigorously. 


The first type of firewall was just a packet filtering firewall. In other words, a device that simply checks where a packet came from, where it's going, and what kind of protocol it has.

But attacks can be hidden in packet data, within the payload itself, so firewalls have had to evolve to check the inside of packets as well.
This evolution has led to the development of different types of firewalls that can perform specific functions, for example:

>>Packet filtering firewalls inspect each data packet as it travels through the network. They decide whether to block a specific packet based on the configured rules.
>>Application layer firewalls can be a physical device that uses its own hardware or software installed on another machine, such as a plug-in or a filter. 
These types of firewalls target applications and monitor their behavior. For example, if placed in front of a Web server, they can inspect requests for HTTP connections and block abnormal floods of traffic that indicate a DOS attack.
>>Circuit-level firewalls check whether TCP and UDP connections on a network are valid before exchanging data. 
For example, this type of firewall may first check whether the source and destination addresses, user, time, and date meet certain defined rules. Data is exchanged between parties without further investigation when these checks are passed and a session is started.
>>Proxy server firewalls control information entering and leaving a network. 
This capability means that the server can monitor, filter, and cache data requests to and from a network. Firewalled proxy servers provide secure Internet access to all devices on a network.

A stateless system sends a request to the server and relays the response (or the state) back without storing any information. 
On the other hand, stateful systems expect a response, track information, and resend the request if no response is received

Stateful firewalls inspect connections on a network. As traffic reaches the firewall, it monitors all packets that pass through it and stores a combination of information about the packets in a state table. 
The state table tracks sessions by recording port numbers as sessions are initiated within the network and transmitted outside the network.
Collecting this information helps the firewall recognize what legitimate traffic with the correct port numbers should look like when returning, thus allowing legitimate responses to return to the network.


Firewall rules

Wherever the firewall is placed, the rules that make up the policy determine what is and is not allowed to enter or leave a network.

Rules are created using a list of elements that the firewall can check. These elements include:

Source address - where the data came from. Typically this is an IP address, but it can also be a fully qualified domain name or FQDN. An FQDN is the name of a device on the Internet, verified by an external DNS server.
Destination address - where the data is going. This is usually an IP address, but can also be a fully qualified domain name (FQDN).
Port and protocol numbers - the services that applications require.
Interface -rules can be associated with a specific interface or port on a firewall.
Direction - whether the traffic is inbound or outbound.
Time - Specifies when data will or will not be allowed.
The decision - whether the packet should be allowed or denied.

When creating firewall protocols, it is important to remember the following three rules:

Top-down processing - A firewall starts at the top of a list of policies and works its way to the bottom, so the order of the rules is critical.

Matching rule - If any incoming traffic matches the criteria of a firewall rule, the firewall applies the specified allow or deny action without moving on to the next rule. 
All other rules below the corresponding rule will not be considered because firewalls implement top-down processing.

Implicit deny - also known as deny everything. Typically, this is an invisible rule applied when a firewall is initially configured and blocks all traffic from the start. 
It allows a firewall to protect the network as soon as it is activated. This rule remains active at all times, so many firewall policies have allow statements (also known as allow statements) 
to allow necessary traffic to pass through. Implicit negation is always the last rule in the list of rules. And since it's active by default and invisible, it's important to remember that it's there.

The implicit deny rule is always present at the bottom of the list of rules. This means that the network is protected from all traffic until more rules are added to allow other types of traffic, 
such as web traffic and email communication, for example.


Microsoft Sentinel with a huge range of products from Microsoft 365 Defender to Microsoft for Cloud Apps. Your endpoints, identity, applications, data, infrastructure, and network are all protected.
Sentinel measures this by collecting data at Cloud-scale across all users, devices, applications, and infrastructure, both on-premises and in multiple Clouds. 
Detecting previously undetected threats using Microsoft's analytics and unparalleled threat intelligence. Investigating threats with artificial intelligence, 
and hunting for suspicious activities at scale by tapping into years of cybersecurity experience at Microsoft. And responding to incidents rapidly with built-in orchestration and automation of common tasks.

 if you only have a few vulnerable areas in your network, Microsoft Defender might be a better choice as it focuses on critical areas.

 Microsoft Defender for Endpoint is a good choice. This product can help look after existing endpoints. And scans for new endpoints as they are added to the network, thus giving some level of protection straightaway. 

Insider attacks
A simple click on a link can grant internal access to an attacker. A firewall cannot prevent this attack, as it comes from what appears to be a trusted source. 
Better security policies and education are needed in this case.
A malicious insider attack is an attack carried out by a user with access to the network who collaborates with an external party. The attack exposes the firewall because internal network access is trusted. 
To better protect the network, network segmentation should be implemented to filter access to sensitive areas.

Network analysis: Identifying threats
Penetration testing
Continuous monitoring - firewalls and tools such as Microsoft Sentinel can send threat alerts from several different sources on the network.


you will need good change control procedures to reduce the most significant risk to firewalls: misconfiguration!!!    https://docs.rackspace.com/docs/best-practices-for-firewall-rules-configuration

Changing a rule in a firewall can prevent something from working or even allow some completely new and unknown risks to pass through the firewall. 
This is why testing a new rule in a test environment separate from the network is so important and helps minimize risks. 
This can be difficult for a small company, so having a good rollback plan is just as important. If something happens that shouldn't, the rollback plan allows you to undo the changes.

https://learn.microsoft.com/en-us/training/modules/network-fundamentals-2/
https://learn.microsoft.com/en-us/training/paths/implement-network-security/
https://learn.microsoft.com/en-us/training/modules/introduction-azure-ddos-protection/2-what-is-azure-ddos-protection
https://learn.microsoft.com/en-us/microsoft-365/security/office-365-security/anti-phishing-protection-spoofing-about?view=o365-worldwide
https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-sstp/4a6778bc-a4a9-46c6-9120-7493c61f95e5
https://learn.microsoft.com/en-us/azure/sentinel/overview


------------ virtualization

But how exactly is virtualization done? In a virtualized environment, a software program called a hypervisor is installed in a computer. 
The hypervisor creates virtual versions of the physical resources, such as virtual CPUs, memory, and storage. 
Hypervisors are the core of Virtualization Technology because they provide the foundation for creating and managing virtual machines or VMs.

Type 1 and type 2. Type 1 hypervisors, also known as bare-metal hypervisors, are installed directly on the host machine's hardware. 
This enables the hypervisor to efficiently create and manage virtual machines without requiring a separate operating system. 
Type 1 hypervisors are often used in data centers and enterprise level environments because they offer better security and isolation than type 2 hypervisors. 
Examples of type 1 hypervisors include VMware, ESXI, Microsoft Hyper V and Citrix Xen server. 
Type 2 hypervisors or hosted hypervisors, on the other hand, run on top of a host operating system. 
These hypervisors are typically used for desktop virtualization, testing environments and personal use. Examples of type 2 hypervisors include Oracle VirtualBox, VMware, Workstation and Parallels Desktop.


--------  How Virtual Machines and Containers Can Help with Networking and Security Testing
Virtual machines and containers are powerful tools for networking professionals to simulate and experiment with virtual networks, infrastructure, and security tools in an isolated environment.

By creating virtual machines, you can simulate and experiment with different network configurations and protocols. 
Virtual machines can create a virtual network with multiple subnets, routers, switches and servers and test the communication process between different devices. 
This is useful for testing different network configurations and protocols and ensuring your network is optimized for performance and security.

Virtualization can also simulate an entire infrastructure, including servers, databases, applications, and services. 
By creating multiple virtual machines and configuring them to work together, you can create a complete infrastructure that can be used for testing and development purposes. 
This is useful for testing new software versions, security patches, and updates in a controlled environment before deploying them to production.

Virtual machines and containers can also run network security tools in isolation. By running security tools in a virtual environment, you can isolate them from the host machine 
and other applications, reducing the risk of damage and security risks exposed to the outside world. This is useful for testing the effectiveness of different security tools, 
such as intrusion detection systems (IDS) and web application firewalls (WAF), against various types of attacks.

Another way to learn how virtual machines can be used for security testing is to create honeypots. A honeypot is a virtual machine or network intentionally designed to attract attackers. 
Creating a virtual machine that looks like a vulnerable system or service can attract attackers and gather information about their tactics and techniques. 
You can also simulate network attacks, such as denial of service attacks or malware infections, and test your network's resilience against these threats.

Virtual machines and containers can be used to test the security of your own network. To simulate network attacks, you can use tools like Kali Linux, 
a popular Linux distribution designed specifically for penetration testing and digital forensics.


-=------------------ XaaS     https://www.techtarget.com/searchnetworking/feature/What-cloud-data-center-interconnect-technologies-can-do


uses a private connection between your on-premises network and Microsoft clouds to better interconnect XaaS services.
https://learn.microsoft.com/en-us/training/modules/intro-to-azure-expressroute/2-what-is-azure-expressroute

Software as a Service (SaaS)
SaaS allows users to connect and use cloud-based applications over the Internet. SaaS applications are also known as hosted applications. 
In general, with SaaS, users don't install any software. They connect through a browser and use hosted software.
Examples of SaaS include video-on-demand platforms like Netflix, Microsoft 365, and apps like Spotify. In fact, most applications that allow end users to make time-based subscriptions are examples of SaaS.


To help you identify a SaaS application or service, you can ask yourself these four questions, 
is the application managed from a central location? 
Is it hosted remotely? 
Is it accessible over the Internet? 
And is the provider responsible for the maintenance?
If the answers to these questions are yes, it's most likely SaaS.


Platform as a Service (PaaS)
PaaS is a complete development and deployment environment in the cloud. Developers and software companies use PaaS to quickly and easily create and publish new programs or 
applications without having to take care of the necessary infrastructure.
PaaS capabilities allow developers to deliver everything from simple cloud-based applications to sophisticated, cloud-enabled enterprise applications. Developers can acquire the features they need from a
cloud service provider on a pay-as-you-go basis and access them via a secure internet connection.
Examples of PaaS include: Microsoft Azure, AWS lambda, and Google app engine.

Reduce coding time. PaaS development tools can reduce the time required to code new applications with pre-coded application components built into the platform, 
such as workflow, directory services, security features, search, and so on.

Add development resources without expanding your team. PaaS solutions provide development teams with new capabilities while reducing the need for additional staff with specialized skills.

Easily develop for multiple platforms. Typically, PaaS offers development options for multiple platforms such as computers, mobile devices, and browsers, making cross-platform app development faster and easier.

Use sophisticated tools cost-effectively. A pay-as-you-go model allows individuals or organizations to use sophisticated development software, business intelligence,
and analytical tools that they cannot purchase outright.

Support geographically distributed development teams. Because the PaaS development environment allows users to connect over the Internet, development teams can work together 
on projects even when team members are in remote locations.

Efficiently manage the application lifecycle. PaaS solutions provide all the capabilities you need to support the complete web application lifecycle: build, test, deploy, 
manage, and update in the same integrated environment.


Infrastructure as a Service (IaaS)
IaaS is a type of cloud computing service that offers computing, storage, and networking resources on demand. 
IaaS offerings enable organizations to eliminate the cost and complexity of purchasing and managing physical servers and data center infrastructure. 
Organizations pay for each resource for as long as it is needed on a pay-as-you-go basis. A cloud computing service provider like the Microsoft Azure
manages the infrastructure, while the customer purchases, installs, configures and manages their own software, including operating systems and applications.

The difference between IaaS and PaaS is that IaaS allows you to manage the operating system and determine the power of the infrastructure you use. 
This could be a better performing CPU or faster storage. This is useful when certain applications require a custom operating system to run efficiently. 
For example, some websites need a high-performance infrastructure to handle very high volumes of requests. 
On the other hand, with PaaS, the infrastructure and operating system are determined by the platform provider.


Your service model will determine responsibility for things like:

Operational systems
Network Controls
Applications
Identity and infrastructure



===========    Cybersecurity Threat Vectors and Mitigation   ===================

https://www.microsoft.com/en/security/business/security-101/what-is-cybersecurity
https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5bUvv?culture=en-us&country=us
https://www.microsoft.com/en-us/security/business/security-101/what-is-a-cyberattack


What is WannaCry?
The WannaCry ransomware attack was a global incident that caused substantial damage in May 2017.
The attack targeted the Microsoft Windows operating system, exploiting a vulnerability known as EternalBlue. 
After infecting a machine, it would encrypt the data and demand payment in cryptocurrency for the data to be restored.

hackers used a vulnerability in Microsoft's Server Message Block or SMB protocol, which is used for file sharing.
The hackers behind WannaCry were able to use EternalBlue to spread ransomware from one system to another very quickly.

WannaCry was diagnosed by a 22-year-old cybersecurity researcher named Marcus Hutchins, who discovered a kill switch in the code. 
he kill switch was surprisingly simple as it was just a domain name. WannaCry was designed in such a way that if it could contact that domain name of the affected computer, 
it would stop encrypting the files on that system. Therefore, no additional damage would be done to that computer if the ransomware was able to communicate with that domain.

That domain name was iuqerfsodp9ifjaposdfjhgosurijfaewrwergwea.com.

The incident highlighted the importance of proactive measures to protect against cyber threats, including implementing robust security protocols and ensuring regular data backups.


Stuxnet Worm
Worms are a type of malware that cause disruption to computer systems. They are self-replicating and spread across networks, exploiting security and software vulnerabilities. 
Unlike viruses, which need host files or programs to attach, worms can spread through various means, such as

email attachments,
text messages,
file sharing programs,
social networking sites,
network shares and
removable drives.

Typically, worms spread by exploiting vulnerabilities in operating systems and software applications to gain access to computer systems. 
Once they gain access, they copy themselves to any other computer that is on the network.

Worms can exploit weaknesses in operating systems or applications to infect computers. After infecting a system, worms look for vulnerabilities, infect the target, and repeat this process, allowing them to spread quickly.

Worms can also copy themselves onto removable USB drives, allowing them to spread to any system the drives are plugged into. This is an easy way for worms to move between systems that are not connected to a main network.

It is also common for worms to trick users into clicking malicious links or downloading and executing infected email attachments. 
This often occurs when users receive fake messages that appear to come from a legitimate source.
When the user opens the attachment, the worm is activated, infecting their system and spreading to other devices on the network.

Another method used by cyber criminals is cracked software, often called pirated software. 
This poses a significant risk to users looking to bypass licensing restrictions and obtain software for free or at a reduced cost.

However, when software is cracked, its original code is altered to bypass licensing and copyright protection mechanisms.

Stuxnet stands out as the malware that altered the world's perceptions of cybersecurity. It was designed with unprecedented sophistication and precision. 
It not only targeted computer systems but also caused physical damage to essential infrastructure.

Stuxnet's primary target was Iran's nuclear program. It specifically targeted the uranium enrichment centrifuges at the Natanz facility. 
When the worm infiltrated the industrial control systems (ICS) that managed these centrifuges, it manipulated their operating parameters, causing them to malfunction and ultimately break down.

Stuxnet manipulated multiple zero-day vulnerabilities in the Windows operating system to infiltrate its target systems, demonstrating an enormous level of technical sophistication. 
These manipulated vulnerabilities allowed the worm to spread undetected and even gain administrative privileges. This allowed it to execute its payload unnoticed.

Stuxnet's modular design allowed it to adapt to various environments and avoid detection by antivirus software. Its payload was created specifically to target supervisory control and data acquisition (SCADA) systems



A Trojan is a special type of malware that can disguise itself as a legitimate file or piece of software. It does this to trick you into downloading and installing it. 
Once the Trojan is installed, the attacker can remotely manipulate your system, allowing them to steal important data and get access to the data or applications on your computer. 
Trojans can even work as key loggers, reading keystrokes and stealing login credentials or credit card information. Unlike viruses, Trojans can't replicate on their own.
Trojans are typically delivered through phishing emails, malicious downloads, or compromised websites. Since Trojans can't replicate like viruses, they are easier to detect and remove.

a virus is a type of malware that infects files or programs, computer systems. It can even spread to other computers through network connections, email, or infected files. 
Unlike Trojans, which needs to be physically installed by a user, a computer virus can replicate and spread itself rapidly once it is infected your machine. 
A virus can be delivered through email attachments, infected software downloads, or malicious websites. 
Viruses are often more difficult to detect and remove, as they can hide in system files and continue to spread to other devices.

Unlike viruses and Trojans, worms don't have to attach themselves to a program or file to infect your system. 
Instead, they can take advantage of vulnerabilities in your operating system and spread from computer to computer, causing considerable damage to your system and network. 
However, just like Trojans, worms can create backdoors to your system, allowing attackers to gain unauthorized access or launch other types of attacks. 
measures you can take to protect your systems and networks against worms, including making sure your operating system and antivirus software has kept up-to-date and don't forget to run regular scans. 

Don't open them unless you're certain they're safe. You should also avoid suspicious websites, especially those that offer free downloads, adult contents, or pirated software. 
Try enabling the pop-up blocker in your browser. This blocks unwanted pop-ups which can contain Trojans or viruses. 
Finally, keep yourself up-to-date with the latest information. Stay knowledgeable on the latest threats and educate yourself on how to protect your device from Trojans and viruses.


A data breach occurs when information is stolen or extracted from a device without the knowledge or permission of the system owner.

This may include:
personal information,
financial data and
confidential business information.

From a cybersecurity perspective, data breaches pose a serious threat; they can result in financial losses, reputational damage and loss of trust.

Data breaches occur in many ways, whether through hacking, malware, social engineering, or even human error.

https://blogs.microsoft.com/on-the-issues/2021/07/20/the-growing-threat-of-ransomware/
https://learn.microsoft.com/en-us/training/modules/introduction-to-threat-vectors-data-breaches/3-examine-how-phishing-retrieves-sensitive-information
https://learn.microsoft.com/id-id/microsoft-365/security/defender/?view=o365-worldwide


===================  threat vectors  ============================

Threat actors, like hackers, use malicious code to deliver viruses to their victims.
Threat actors represent human beings who use different entry points to gain unauthorized access to computer systems.
These entry points, known as threat vectors, include malicious URLs, USB storage with malware, and phishing emails.


 A threat actor is the individual or group that engages in malicious activity that compromises the security of computer systems networks or other digital assets. 
Threat actors use a threat vector to gain unauthorized access to your system. 
So, a threat vector is the entry point for attackers to gain access to a system or organization


 watering hole attack
This is another primary threat vector that involves malicious websites or downloads 
This attack involves purposefully injecting a website with malware that employees of a specific organization are known to visit frequently and redirecting them to malicious websites without their knowledge.
These tactics compromise user systems by exploiting vulnerabilities in the organization's web browsers. 

Zero day vulnerabilities refers to previously unknown flaws in software or hardware. Which can be exploited by attackers before developers have a chance to release a patch

Internet of things devices, such as your smart home appliances and wearables.
Lack of adequate security measures, default passwords or poorly configured systems can make them threat vectors. 

mobile devices including your cell phone or tablet, could be targeted through malicious apps. 

Smishing known as SMS phishing or phishing. Also referred to as voice phishing, an. An exploitation of Bluetooth or WiFi vulnerabilities. 


Macros are a powerful method of automating common tasks and improving productivity within Microsoft Office
, cybercriminals also use macro malware functionality to infect your device. Delivered via an email attachment or zip file, the macro works by hiding in your Microsoft Office files. 
The email attachments uses names intended to entice or scare you into opening them.

 rootkits, which cybercriminals use to hide malware inside your device. This allows the malware to possibly remain undetected for years, allowing it to steal your information and resources. 
Rootkits can also intercept and change standard operating system processes and adjust system reports to evade detection. 

fileless malware, which is unique because it functions without installing malware or other programs on your computer's hard drive. 
Instead, fileless malware makes use of existing programs or tools already installed in your computer. This method makes it challenging for antivirus software to locate it. 

Microsoft data shows that the energy sector is one of the most targeted sectors for ransomware, as well as the financial, health care, and entertainment industries.


Metamorphic malware works in a similar way, continually changing its code and maintaining the same functionality.
It does this by using obfuscation techniques to alter your code. Metamorphic malware can rearrange blocks of code, insert unwanted code, rename variables, and more, 
all to generate a new variant of itself that looks different on the surface but does the same thing.

Because metamorphic malware is constantly changing its code, it is difficult for traditional detection methods to detect it. 
This obfuscation makes it difficult and requires a lot of time, skill, and effort to inspect these malware programs and raises the bar for analyzing new threats. 
Researchers have turned to heuristic and behavioral analysis to identify these shape-shifting threats, which remains a challenge.

Heuristic analysis 
is based on previously established rules to determine whether something is a threat or not. Analysis takes advantage of all previous analysis or experience.

behavioral analysis 
which examines the purpose of a file and can determine whether that purpose is a threat or not. 
If a file is studied and its only function is to exclude other files, this behavior corresponds to that of a virus, the file can be isolated and an alert can be triggered.

Just like metamorphic malware, polymorphic malware also changes its code to avoid detection. But instead of obfuscating itself, polymorphic malware encrypts its malicious code after infecting a system. 
It carries its encrypted code along with a decryption module to unlock it. You can think of it as a chameleon, which can quickly change the color and pattern of its skin to suit its surroundings. 
Likewise, by generating a new encryption mechanism with each infection, polymorphic malware alters its code so that it constantly changes to match its environment, which allows it to hide in plain sight.

To avoid detection and maintain their command and control infrastructure, attackers often use fast flow techniques or DGA (Domain Generation Algorithms). 
Fast flow involves rapidly changing IP addresses associated with malicious domains, while DGA generates a large number of domain names to establish communication channels. 
Both techniques make it difficult for security solutions to identify and block malicious traffic.


Signature-based detection alone is not effective against these ever-changing threats. Heuristic and behavioral analysis helps identify malware even when its appearance is changing. 
Machine learning and neural networks can also learn the patterns of metamorphic and polymorphic malware to detect even its most advanced variants.

Some software solutions, such as antivirus software, are designed to scan, detect, and remove known viruses, worms, and other types of malware from computer systems.

There is also anti-malware software, which detects and removes malicious software, including Trojans, spyware, adware, and ransomware.

Email security solutions are also available and are designed to protect organizations and individuals against email-based threats such as phishing, spear-phishing, 
and malware delivered through email attachments or links.

Organizations must make sure they have solid security policies in place. These policies must include:
Strong passwords and multi-factor authentication (MFA).
Robust security solutions such as firewalls and specialized detection software.
Mandatory software security updates.


https://www.statista.com/statistics/494947/ransomware-attempts-per-year-worldwide/
https://www.statista.com/statistics/700965/leading-cause-of-ransomware-infection/


Typosquatting
Another threat vector is typosquatting or URL hijacking. Attackers use typosquatting to create malicious websites with domain names similar to popular, trusted websites, 
hoping that victims will mistype the URL and visit the malicious website. For example, using CompanyName.cm instead of CompanyCame.com. Victims then enter login credentials or 
personal data into the malicious website, allowing attackers to steal this information.

You can protect yourself against typosquatting by:
be cautious when typing URLs,
using bookmarks for frequently visited sites and
keeping a close eye on domain names with slight spelling errors.

SQL Injection
Many databases use the SQL language to quickly process data stored in the database. However, another threat vector, called SQL injections, can exploit vulnerabilities in web applications that use SQL databases.

Attackers inject malicious SQL code into forms or URLs to manipulate the database, gain access to sensitive data, or execute commands. This is a serious risk and can give attackers full access to the database. 
Programmers must always properly sanitize and validate user input when developing software and web applications to prevent SQL injection attacks.



you should also avoid having any private information or passwords on websites or in plain sight, such as in a file on your computer or written down. Instead, use a secure password manager to store your sensitive information, 
and always double-check the website's URL and security certificate before entering your credit card details.

One of the best mitigation strategies you can implement is to install a reliable antivirus and firewall. 

keep yourself up-to-date on the latest cybersecurity threats, and best practices to protect your digital life.


Types of Biometric Security Systems
Eye scanning involves two main types:

Firstly, the iris scan, which captures the pattern of the colored ring around the pupil. Iris scanning is non-intrusive, highly accurate, and provides fast authentication,
but can be sensitive to lighting conditions and certain eye conditions or glasses.

Next comes the retinal scan, which captures the pattern of the blood vessels at the back of the eye. Retinal scanning is extremely accurate, but it can be intrusive, slower and more expensive to implement.

Fingerprint recognition

Facial recognition

Other methods
Other biometric security methods include voice recognition, palm print scanning, and behavioral biometrics such as keystroke dynamics, among others.

Disadvantages of biometric systems
However, despite their benefits, biometric systems have some disadvantages, including

Privacy Concerns: The collection, storage and processing of biometric data raises privacy concerns as this information can be used for unauthorized purposes if not properly protected.

False positives and negatives: Biometric systems can accidentally generate false positives (grant access to the wrong person) or false negatives 
(deny access to the correct person), especially if the system is not well maintained or calibrated or if there are hardware problems.

Implementation costs: Implementing biometric security systems can be expensive, especially with more advanced technologies such as retinal scanning.


password managers have become a very useful tool for generating and saving complex and unique passwords for all your logins. 
Password managers encrypt and store your passwords and login information in one place. Some of them can even automatically log you into websites and apps, so you never have to manually enter your credentials again. 
There are several password manager applications you can use, including LastPass, 1Password, and Bitwarden. Most of these password managers even support a secondary authentication layer, like one-time pin or OTP,
which adds additional protection. While password managers are useful and create very secure passwords, it's also beneficial that you understand how to create a secure password yourself. 


Do not include your name, a family member's name, or a pet's name. They are too easy to guess. It should not include phone numbers, birthdays addresses, or social security numbers.
Cybersecurity experts recommend creating a new password every three months. 

two-factor authentication can protect your online accounts by adding an extra security layer. There are several applications that offer two-factor authentication, 
including Microsoft authenticator, Google authenticator, and Authy. They generate time based one-time passwords or OTP for multi-factor authentication. 
On top of all these options, you also have personal encryption tools like GPG or GNU Privacy Guard, and Pretty Good Privacy or as it's known, PGP.
These help protect sensitive information by encrypting files and messages, ensuring only authorized recipients can access them. These tools use public key cryptography to enable secure communication and file sharing. 
Applications like Microsoft Bitlocker and macOS File Vault provide full disk encryption, scrambling your entire hard drive and all its contents.

How do antivirus programs detect malware?
Signature-based detection
The first is signature-based detection, which is the most traditional method of identifying malware. 
This technique relies on the antivirus program's virus database, which contains unique signatures or patterns of known malware. Antivirus software scans files and compares them to database signatures. 
If a match is found, the file is flagged as malicious.

However, signature-based detection has its limitations. It can only identify known malware and is less effective against new or previously unknown threats,
which is why it is often combined with other detection techniques.

Heuristic analysis
Next comes heuristic analysis, which involves examining a file's code, structure, or behavior to identify potential threats. 
This technique allows antivirus programs to detect previously unknown malware or new variants of existing malware. Heuristic analysis uses algorithms to determine whether a 
file exhibits characteristics commonly associated with malicious software.

However, heuristic analysis can generate false positives because some legitimate programs share features or behavior patterns with malware. 
However, it is a valuable tool for identifying new threats that may not yet have a signature in the virus database.

Behavioral analysis
Cybersecurity can also complete behavioral analysis by monitoring the real-time actions of software on a system to identify potential threats. 
This method is based on the principle that malware will engage in malicious behavior, such as modifying system files, installing unauthorized software, or accessing sensitive data.

If a program exhibits suspicious behavior, antivirus software will flag it as a possible threat and block its actions or quarantine the file for further investigation. 
This approach is useful for detecting malware that may evade heuristic or signature-based detection methods.


How firewalls work

One of the fundamental techniques used is packet filtering, which involves inspecting each data packet that passes through the firewall and determining whether to allow or block it based on predefined rules. 
These rules typically include criteria such as IP addresses, port numbers, and protocol types.

For example, a rule can be defined to block all inbound traffic from a specific IP address or to only allow HTTPS traffic through a certain port. 
Packet filtering is a relatively simple and efficient method for controlling network traffic, but it may not be sufficient to protect against more sophisticated threats.


Stateful inspection, also known as dynamic packet filtering or stateful firewall, adds an additional layer of security by maintaining information about the state of active connections. 
This approach allows firewalls to examine not only individual packets, but also the context of the connection over which they are transmitted.

When a connection is established, the firewall records the connection details in a state table. As packets pass through the firewall, they are compared to the state table to determine 
whether they belong to an existing, authorized connection. This method allows firewalls to detect and block unauthorized or malicious packets that may attempt to exploit legitimate connections.

Another technique used is application layer filtering, also known as deep packet inspection or proxy-based filtering. It involves examining the contents of data packets at the application layer of the OSI model. 
This technique allows firewalls to inspect the actual data being transmitted by applications, enabling the detection and blocking of specific types of content,
such as malware, spam, or unauthorized access to sensitive information.


Data backup
One of the best solutions to prevent data loss is to maintain a regular backup of your data. This not only ensures data security, but also saves you from having to put in a lot of effort to create that data again. 
There are several types of software that help you create regular backups of your computer data and store it on physical hard drives, SSD drives, or a cloud storage solution such as 
Microsoft OneDrive, Google Drive, Google Photos, or Dropbox.


Some popular encryption tools for full disk encryption are Microsoft Bitlocker for Windows operating system, VeraCrypt for Linux, and FileVault for macOS. 
You may be surprised to learn that the operating system continues to function like a normal machine, even when the disk is encrypted with these tools. 
While there may be a small reduction in performance due to the encryption and decryption processes, modern hardware and encryption algorithms have minimized this performance impact, making it negligible for most users.

It is critical to be aware that malware programs can still access files on an already encrypted disk if they gain access to the system while it is unlocked and running.


Preventing data theft from your device

Back up your data: Before selling or disposing of a device, make sure you have a complete backup of your personal data.

Log out of account: Log out of services like iTunes or Google and any other personal accounts, including email, social media, and cloud storage services.

Factory reset your device: Perform a factory reset on your computer or phone to remove all your personal data and restore your device to its original settings. In the case of computers, 
this may involve reinstalling the operating system.

Securely Erase Hard Drive: Always use a secure erase tool to overwrite your hard drive or SSD multiple times, ensuring that it cannot be recovered easily. Some operating systems 
have built-in tools for this purpose, such as "Secure Delete" on macOS. On Windows, you may need to use command-line tools or third-party software.

Physically destroy storage: If you are disposing of a hard drive, SSD, CD, or USB drive and want to ensure data security, consider physically destroying the drive.



============== encryption ================


encryption is the process of encoding a message or data so that only authorised parties with the right key can access it. 
encryption is asymmetric encryption. Unlike symmetric encryption, which relies on a single shared key for encryption and decryption, asymmetric encryption uses a pair of keys. 
This pair consists of a public key and a private key. 
The public key is responsible for encrypting the message and can be shared with anyone, while the private key is responsible for decryption and must be kept secret

Many other types of encryption techniques are also used in modern day cryptography, such as hash functions, digital signatures and key exchange protocols.
These techniques are used to protect data and communications in a variety of different scenarios, from securing online banking transactions to protecting military communications.


Data Encryption Standard (DES)
In the 1970s, the Data Encryption Standard (DES) was developed by the US government to provide secure communication between its agencies. DES used a 56-bit key

Advanced Encryption Standard (AES)
To address this vulnerability, the Advanced Encryption Standard (AES) was developed in the late 1990s. AES is a symmetric encryption algorithm, meaning that the same key is used to encrypt and decrypt data. 
It divides data into smaller blocks of 128 bits and encrypts each block separately with a key size of 128, 192, or 256 bits, a technique known as a block cipher. 
AES is considered one of the most secure encryption algorithms in use today.

To understand how AES works, let's say Sam has a recipe for his famous ice cream that he wants to keep secret. Sam uses AES to encrypt his recipe. First, the revenue is divided into blocks of a fixed size. 
Then each block is encrypted using a key. This means that Sam's income is divided into thousands of individually encrypted blocks that are then put together and encrypted as a whole. 
The key is a secret code that is used to encrypt and decrypt data. Only Sam has the key to decrypt the recipe. This ensures that your recipe remains a secret.

Public key cryptography
In traditional symmetric key encryption, both the sender and receiver must have access to the same key. However, with public key cryptography, each user has a public and a private key. 
The public key can be shared with anyone, while the private key is kept secret. This allows secure communication without the need to share a secret key.


RSA encryption is based on mathematical functions with large prime numbers, which makes it almost impossible to break. It uses two keys, one public and one private, to encrypt and decrypt data. 
The public key can be distributed to anyone who wants to send encrypted data, and the private key is kept secret by the recipient. 
RSA encryption is widely used in digital signatures, secure email, and other applications that require secure communication.

To understand how RSA encryption works, let's consider Sam's Scoops once again. Sam wants to send a secret message to his business partner, Sally. Sam uses RSA encryption to encrypt the message, generating a public and private key pair. 
Sam shares the public key with Sally, who uses it to encrypt her response to Sam. Then Sam uses his private key to decrypt Sally's response.


Secure Sockets layer (SSL) and Transport Layer Security (TLS)
In addition to traditional encryption methods, the development of the Internet has led to the creation of new encryption protocols, such as SSL/TLS. SSL (Secure Sockets Layer) was developed by Netscape in the 1990s 
as a way to secure online transactions. It was later replaced by TLS (Transport Layer Security), which is used to secure communication between web servers and clients. SSL/TLS is used in a wide range of applications, 
including online banking, e-commerce, and email. SSL/TLS uses a combination of symmetric and asymmetric encryption to provide secure communication between two parties.
Asymmetric encryption is used to establish a secure channel, and symmetric encryption is used to encrypt data that is transmitted over the channel.

For example, imagine that Sam wants to create an online store to sell his products. To ensure the security of his customers' transactions and confidential information, Sam uses SSL/TLS to protect his online store:

When a customer visits Sam's online store, their browser initiates a connection to Sam's server.

Then the server sends your SSL/TLS certificate to the browser.

The browser checks the certificate and, if it is valid, a secure connection is established between the browser and the server.

All data exchanged between the browser and the server is encrypted, ensuring that it cannot be intercepted by an attacker.


Elliptical Curve Cryptography, or ECC. ECC is a type of public key encryption that is based on the mathematical theory of elliptical curves and uses smaller, faster, and more efficient keys. 
Instead of multiplying large prime numbers like traditional methods, ECC uses an elliptical curve equation to link two separate keys to encrypt and decrypt data. One is a public key and the other is private. 
This approach offers a higher level of security because the private key cannot be derived from the public key. ECC is an alternative to the RSA cryptographic algorithm and is widely used in cryptocurrencies such as, 
Bitcoin and Ethereum.
And because it is so efficient, it works well for wireless communication and the Internet of Things. 

 AES can be challenging when multiple parties are involved. RSA's complexity can slow down the encryption process, and while 
ECC offers a higher level of security, its complexity makes it vulnerable to implementation errors

Key management practices involve procedures for generating, distributing, storing, and revoking encryption keys. And ensures that only authorized parties have access to them. 
This is essential for maintaining the confidentiality and integrity of encrypted data. One of the most popular key management practices is the use of key exchanges.
Key exchanges allow for the secure distribution of encryption keys between parties without the need to share the key itself. A popular key exchange protocol is the Diffie-Hellman Protocol. 
Which allows two parties to independently generate shared secret keys without actually sharing the key itself. 
This protocol is commonly used in secure communications and e-commerce transactions.
When it comes to choosing the right encryption technology, various fact such as the level of security required, the size of the data, and the number of parties involved need to be taken into account. 
Symmetric encryption methods like AES provide fast and efficient encryption. While asymmetric encryption methods like RSA and ECC offer more versatility and security for multiple parties.


Pretty Good Privacy (PGP)
PGP is a widely used encryption tool that allows the secure transmission of sensitive information, such as emails and text messages, through end-to-end encryption. 
It uses a combination of symmetric-key and public-key cryptography to ensure that only the sender and recipient can access the message content.
PGP offers an intuitive interface that allows users to encrypt and sign their emails and messages. The sender encrypts the email message with the recipient's public key, 
and the recipient decrypts the message with their private key.
PGP uses a digital signature to verify the sender's identity, ensuring that the message has not been tampered with. Additionally, PGP can also encrypt files and folders to increase security.

Bitlocker and FileVault
Bitlocker and FileVault are encryption tools used to protect data on Windows and macOS operating systems. These tools encrypt the entire hard drive, including the operating system and all user data. 
This ensures that even if the computer is lost or stolen, the data cannot be accessed without the appropriate decryption key.
Bitlocker uses the Advanced Encryption Standard (AES) algorithm to protect data. FileVault is a similar encryption tool built into Mac OS.


VeraCrypt/TrueCrypt
VeraCrypt and TrueCrypt are open source encryption tools that can be used to encrypt individual files or entire disks. They use several encryption algorithms, including AES. 
VeraCrypt and TrueCrypt also offer plausible deniability, meaning encrypted data can be hidden in plain sight, making it harder for attackers to find and access it.

VeraCrypt and TrueCrypt are encryption tools used to create encrypted containers, which are files that can store encrypted data.
These containers can be mounted as virtual drives and the data can only be accessed with the appropriate decryption key. 
One of the advantages of using VeraCrypt and TrueCrypt is that they are open source software, which means they are free to use and can be audited by security experts to ensure their security.

End-to-end encrypted messages
End-to-end encryption is a security protocol that ensures that only the sender and recipient can read the message. It uses a key-based system similar to PGP. 
Popular messaging apps like WhatsApp, Signal, and Telegram use end-to-end encryption to protect their users' messages.

End-to-end encrypted messages are considered highly secure as messages are encrypted on the sender's device and can only be decrypted by the intended recipient's device.

https://learn.microsoft.com/en-us/dotnet/standard/security/encrypting-data
https://learn.microsoft.com/en-us/windows/security/operating-system-security/data-protection/bitlocker/
https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/vpn/vpn-connection-type
https://learn.microsoft.com/en-us/training/modules/intro-to-blockchain/


-----------  symmetric key encryption  

how are these keys created? Private keys are created by generating a sequence of bits, or 1s and 0s, that serve as the key itself.
Once generated, the private key is used to encrypt the data, and only the same private key can decrypt the encrypted data. 

AES, is a widely used symmetric key encryption algorithm. It operates as a block cipher, dividing data into fixed sized blocks of 128 bits.
The encryption process involves applying a series of mathematical operations, known as rounds, to the input data. 
The number of rounds depends on the key size, for instance, 10 rounds for 128 bit keys, 12 rounds for 192 bit keys, and 14 rounds for 256 bit keys.

 A larger key size generally provides greater security, making it harder for cyber criminals to crack the code. 
However, it's essential to note that the larger key sizes may result in slower encryption and decryption times. 

AES operates in various modes, each with its unique characteristics and strengths.

electronic codebook, or ECB, is the simplest and most straightforward mode. In this mode, data is divided into blocks, and each block is encrypted independently, however, this simplicity comes with the downfall. 
ECB can be vulnerable to certain attacks, making it the least secure option.

 cipher block chaining, or CBC, encrypts each block of data using the previous block cipher text, creating a chain of interconnected blocks. 
This creates an extra layer of protection, making it more secure and commonly used in situations where confidentiality is very important. 

symmetric key encryption algorithm Blowfish. Blowfish is a symmetric key encryption algorithm designed by Bruce Schneier in 1993. Just like AES, Blowfish is a block cipher that operates in both ECB and CBC modes
 One standout feature of Blowfish is its flexible key size. With Blowfish, you can use variable-length keys ranging between 32 and 448 bits, 
making it a more efficient solution for scenarios that require swift encryption and decryption. 
While Blowfish is ideal for fast encryption, it's important to note that alternative methods like AES may be more suitable in situations where a high level of security is required. 


------------- key management

One solution to address the key management challenges is the use of hardware security modules.
Hardware security modules are physical devices specifically designed to provide secure key storage and cryptographic operations. 
Their tamper resistant properties make them resilient to physical attacks such as drilling, cutting, or heating.
Hardware security modules are commonly used in industries such as finance, healthcare, and government, where the security of cryptographic keys is of utmost importance.
Another option for storing private keys is to use encrypted key storage services, these services use encryption to protect keys stored on their servers. 
While access to the keys is typically protected by multi-factor authentication and other security measures. It is also crucial to establish secure backup and storage mechanisms for private keys. 
Regularly backing up keys helps mitigate the risk of key loss in the event of hardware failure or other unforeseen disasters. 
However, it is equally important to store the backup securely to prevent unauthorized access


AES operating modes
AES has several modes of operation, which are used to provide different levels of security and performance. 
The most commonly used mode is Cipher Block Chaining (CBC) mode, which provides encryption and secure description of data blocks. 
Other modes include Electronic Codebook (ECB) mode, which is used to encrypt small data details, and Counter (CTR) mode, which is used for streaming data.

Another technique used in AES is Galois Counter Mode (GCM), which is a mode of operation for block ciphers. GCM is a combination of Counter mode of encryption and Galois field multiplication.
GCM guarantees the security and confidentiality of the data being transmitted. GCM is widely used in secure communication protocols such as Transport Layer Security (TLS) and Internet Protocol Security (IPsec).


AES Vulnerabilities and Mitigation
AES has also been subjected to several attacks, which has led to the development of new techniques and variants of the algorithm. 
One such attack is the side channel attack (SCA), which involves using information obtained from the physical implementation of the algorithm to extract the secret key.
SCA can be avoided by using techniques such as masking and blinding, which involve adding random values ​​to data during encryption and decryption.

The chosen text attack is another vulnerability that affects AES. In this attack, the attacker can actively select the plaintext to be encrypted and deduce the key using the resulting ciphertext.
To prevent this attack, AES was modified to use whitening techniques. These techniques involve adding a random value to plaintext before encryption and removing it after decryption. 
This makes it more difficult for an attacker to discover the key.

AES has also been modified to provide authenticated encryption, which not only ensures confidentiality but also data integrity.
Authenticated encryption involves using a message authentication code (MAC) to ensure that data has not been tampered with during transmission.

https://learn.microsoft.com/en-us/archive/msdn-magazine/2003/november/aes-keeping-your-data-secure-with-advance-encryption-standard

--------- asymmetric key encryption 

Public key encryption is used for secure communication over unsecured networks, such as the Internet

There are different types of asymmetric key encryption algorithms such as RSA, Diffie-Hellman, and ECC. As you may recall, 
RSA is a public key encryption algorithm widely used for secure communication and data transmission over networks.

he RSA algorithm is based on the mathematical properties of prime numbers, generating two large prime numbers, P and Q, and calculating their products. 
The resulting number is used as the modulus for the encryption and decryption process
To decrypt the message using RSA, the receiver uses the private modulo as part of an equation that allows the message to be divided by their private key to obtain the original message.

RSA offer several advantages, including security, scalability, and efficiency. However, it also comes with challenges related to key management and performance

RSA key generation
You must generate the public and private keys before performing the functions to create the ciphertext and plaintext. This process uses specific variables and parameters that are contained in the algorithm.
The short story is that two very large prime numbers are selected or generated. 
By multiplying these two numbers, you obtain a number that can be used as a module. This number is vital in both the encryption and decryption process.

RSA encryption process
The RSA encryption process involves the following steps:

Key generation: The first step in the RSA encryption process is to generate a pair of public and private keys. 
The public key is shared with anyone who wants to send data securely, while the private key is kept secret by the owner.

Message encryption: To encrypt the message using RSA, the sender uses the receiver's public key to perform the encryption. 
First, the sender converts the message into a number and then raises it to the modulus power of the receiver's public key. The result is then divided by the exponent of the receiver's public key.

Message transmission: The encrypted message is then transmitted over the network to the receiver.

RSA decryption process
The RSA decryption process involves the following steps:

Message reception: The receiver receives the encrypted message over the network.

Key generation: The receiver uses his private key to decrypt the message.

Message decryption: To decrypt the message using RSA, the receiver raises the encrypted message to the modulus power of his private key. The result is then divided by the exponent of your private key to get the original message.


Disadvantages
Although the RSA algorithm is widely used and offers many benefits, it is important to be aware of its challenges. These challenges include:

Key management: One of the main disadvantages of the RSA algorithm is the complexity of key management, especially in large organizations. Because RSA is based on large prime numbers, key generation and secure storage can be challenging. 
Managing a large number of keys can become complicated and requires careful implementation.

Performance impact: Using large keys in the RSA algorithm can significantly affect performance, especially when encrypting or decrypting large messages. 
The computational complexity of the algorithm increases with larger key sizes, resulting in slower processing times. This may be a concern in situations where time-sensitive operations are required.

Like the RSA algorithm, ECDSA involves generating a public key and a private key. However, unlike the RSA algorithm, ECDSA uses elliptic curves to create the public key and private key. 
This allows the keys to be much smaller than those used in the RSA algorithm while maintaining the same level of security.

Using smaller keys also means that ECDSA is faster than the RSA algorithm. This makes it suitable for use in applications where speed is important, such as mobile devices and the Internet of Things (IoT).

Despite its advantages, ECDSA is still not as widely used as the RSA algorithm. This is because RSA has been around for much longer and has already been adopted by a wide variety of companies and organizations. 
However, as the need for greater security and efficiency continues to grow, it is likely that ECDSA will be applied to more and more applications in the future.


The Diffie-Hellman algorithm is a key exchange algorithm used to establish a shared secret between two parties over an unsecure communication channel. 
It is used for sharing the keys for symmetric encryption. The Diffie-Hellman key exchange process involves key generation, key exchange, shared secret generation, and encryption and decryption. 
The algorithm offers benefits such as security, scalability, and efficiency. 
However, it is important to be aware of potential vulnerabilities such as man-in-the-middle attacks and challenges related to key distribution. 

ECC, the elliptical curve cryptography algorithm. You may recall that ECC is a public key encryption algorithm that uses elliptical curves over specific fields to perform cryptographic operations.
The ECC encryption process involves key generation and message encryption. 
ECC brings advantages such as enhanced security, smaller key sizes, and faster computation. However, like any algorithm, it also has its share of challenges, including key management and patent issues.


--------- The formation of digital signatures
https://support.microsoft.com/en-au/office/introduction-to-digital-signatures-d2f92222-abb1-486b-bc07-884ecac99c59
https://learn.microsoft.com/en-us/windows-hardware/drivers/install/digital-signatures
https://support.microsoft.com/en-gb/office/digital-signatures-and-certificates-8186cd15-e7ac-4a16-8597-22bd163e8e96#__toc311530578

 You are electronically sending an important document to a business partner or submitting a confidential form online. 
How can you know that the document has not been tampered with during transmission? How can you verify its authenticity? This is where digital signatures come into play.

Digital signatures have become increasingly common and essential for authenticating digital documents and ensuring the integrity of the information being exchanged between parties.


Digital signatures are used to verify the authenticity and integrity of digital documents or messages, while MACs are used to verify the integrity of data transmitted over a network.

--------------- hashing   https://learn.microsoft.com/en-us/dotnet/standard/security/cryptographic-services
https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/feature-hashing?view=azureml-api-2


hashing algorithms play a vital role in protecting your sensitive data.

Hashing involves converting plain text into a unique, fixed-length sequence of characters known as a hash.

what happens when you enter your password in something like your banking app, social media, or email? 
How do service providers securely match the password you provide with the one you initially signed up with? 
And if this information is saved somewhere, like a database, how do they ensure that your password remains out of the reach of malicious actors? Well, this is where hashing comes into play. 
A powerful technique that transforms your password into a string of characters that's almost impossible to decipher.

Hashing is a process that takes input like your password or any other information and turns it into a fix string of bytes, typically in the form of letters and numbers.
This output is called a hash or a digest and is unique for each input.
So even a slight change in the input will result in a completely different hash.

storing passwords as hashes rather than plain text ensures that even if the database is compromised, attackers cannot easily extract the original passwords. 
But hashing is not limited to password storage. It also plays a crucial role in ensuring data integrity and enabling digital signatures. 

There are different types of hashing algorithms. MD5 is a widely used algorithm that produces a 128-bit hash value, 
but it is no longer considered secure for sensitive applications due to its vulnerability to collision attacks where two different inputs produce the same hash.
However, can still be used for noncritical tasks like generating unique IDs or verifying the integrity of non-sensitive files during data transfer. 

SHA256 is extensively used in applications such as digital signatures, password hashing, and blockchain technology. 

even these robust algorithms can be vulnerable to certain types of attacks, such as brute force and dictionary attacks.
to bolster the security of hash passwords, a technique called salting comes into play. A salt is a randomly generated unique value that is combined with your password before hashing.
This technique guarantees that even if you and another user share the same password, the respective hashes will be different due to the distinct salts. 
This mitigates the risk of identifying users with the same password by simply comparing hashes, making it harder for attackers to exploit common or weak passwords. 
Salts are stored in the database alongside the hashes, which is crucial when you try to log into your account. 

 when you enter your password, the system retrieves the associated salt, which is then combined with the entered password. The resulting value is then hashed and compared to the stored hash.

This approach not only enhances the security of hashes but also prevents attackers from using precomputed hash tables, such as rainbow tables, to crack passwords. 
By implementing unique salts for each user, the attacker's task of matching hashes become significantly more difficult and time-consuming, as they would have to recompute hash tables for each salt value.


-------------- Secure Hash Algorithm (SHA)

SHA is a family of cryptographic hash functions developed by the National Security Agency (NSA) of the United States. The most commonly used versions of SHA are SHA-1, SHA-2 and SHA-3.

SHA-1
SHA-1 generates a 160-bit hash value and has been widely used in the past. However, its use is no longer recommended due to its vulnerability to collision attacks. 
In a collision attack, two different inputs produce the same hash value, which can lead to data tampering and forgery.

SHA-2
SHA-2, on the other hand, generates hash values ​​of 224, 256, 384, and 512 bits, which makes it more secure than SHA-1. It is commonly used for digital signatures, data integrity checks, and password storage. 
SHA-2 uses the Merkle-Damgard construction, which means it divides the input message into blocks, and each block is processed separately. This makes SHA-2 more resistant to collision attacks.

SHA-3
SHA-3 is the latest addition to the SHA family and is designed to be more secure than SHA-2. It generates hash values ​​of 224, 256, 384, and 512 bits and is commonly used for digital signatures, 
data integrity checks, and password storage. SHA-3 uses sponge construction, which means it absorbs the input message and then extracts the hash value.
This construction provides a high level of resistance to collision attacks and is more efficient than the Merkle-Damgard construction used in SHA-2.


Message Digest 5 (MD5)
MD5 is a widely used hashing algorithm that was first introduced in 1991. It generates a 128-bit hash value, which makes it faster and more efficient than some other hashing algorithms. 
MD5 is commonly used for password storage and data integrity checks.

Although MD5 works similarly to SHA-1, it is no longer recommended for use in cryptographic applications due to its small output size and vulnerability to collision attacks.

RIPEMD (RACE Integrity Primitives Evaluation Message Digest)
RIPEMD is a family of cryptographic hash functions that includes RIPEMD-128, RIPEMD-160, RIPEMD-256, and RIPEMD-320. RIPEMD-128 generates a 128-bit hash value, while RIPEMD-160, RIPEMD-256, 
and RIPEMD-320 generate 160-, 256-, and 320-bit hash values, respectively. RIPEMD is commonly used for data integrity checks and digital signatures.

BLAKE2
BLAKE2 is a cryptographic hash function based on the BLAKE algorithm. It supports 256-bit and 512-bit hash values ​​and is designed for performance on modern CPUs. 
BLAKE2 is commonly used in secure communication protocols, data integrity checks, and password storage.

Tiger
Tiger is a cryptographic hash function that generates a 192-bit hash value. It is commonly used in digital signatures, data integrity checks, and password storage.


https://learn.microsoft.com/en-us/dotnet/standard/security/cryptographic-signatures


---------- digital signatures

Digital signing is the process of using cryptographic techniques such as RSA and ECDSA to authenticate digital documents or messages
Digital signing and signatures provide a solution to ensure trust and authenticity. 

Digital signatures are the unique string of characters generated during the digital signing process. They are created using the sender's private key and the signed data. 
Digital signatures serve two primary functions, authenticity and integrity. 
Authenticity means that the recipient can verify the sender's identity, or in other words, the document really came from whom it claims to be from. 
And integrity means that the recipient can check if the document has been tampered with since it was signed. 


------------- digital certificates

her customer's shoes. They want to explore Sam's Scoops' online offerings but they may have concerns about the legitimacy and the security of the website they're about to visit. 
This is where digital certificates fulfill an essential role. They act as electronic credentials that validate the identity of entities and ensure secure communication over the Internet. 

In Sam's case, a digital certificate serves as a stamp of authenticity, assuring her customers that they are indeed visiting the right website. 
Digital certificates are electronic documents that are issued by trusted organizations known as Certificate Authorities or CAs. 
Certificate Authorities play a crucial role in verifying an entity's identity by following strict protocols and adhering to industry standards. 
Digital certificates guarantee that the certificate holder is who they claim to be. 
They contain key information including the website's name, like Sam's Scoops, the certificate holder's name, a public key for secure communication, the CA's digital signature, and the certificate's validity period.

The process to obtain a digital certificate involves several key steps. First, the entity. 
For example, Sam's Scoops requests a certificate from a CA then the CA verifies the entity's identity following stringent guidelines. 
Once the entity is verified, the CA issues a signed digital certificate containing the entity's public key.
The certificate is then installed on the entity's server, and the server uses it to establish secure connections with clients. 
When a user views the website, the client, in this case, the web browser, checks the server certificate for validity. 
Then the client verifies the CA's digital signature on the certificate, ensuring the certificate's authenticity. 
Finally, if the certificate is valid, the client establishes a secure encrypted connection with the server using the public key.

Secure Socket Layer and Transport Layer Security certificates, or SSL and TLS for short, are two common types of digital certificates used to secure communications on the Internet. SSL is the predecessor to TLS. 
While SSL is still used in some contexts, TLS is the newer and more secure protocol. Both SSL and TLS certificates use asymmetric encryption to secure data transmission between a client and a server. 

SSL and TLS certificates have a wide range of applications including securing web transactions, email communications, remote access, and IoT devices.
E-commerce websites rely on SSL and TLS certificates to protect customer data and ensure secure online transactions.

 Email Encryption certificates, also known as S/MIME certificates, verify the sender's identity and ensure the email content remains confidential. 
Organizations can use SSL and TLS certificates to secure their internal communication channels, such as intranets, VPNs, and messaging applications.

What are secure certificates?
Secure certificates, also known as digital certificates, are electronic documents that serve as proof of identity for websites and other online services. 
They allow secure communication between your browser and a website's server, encrypting the data transmitted between them.

SSL Certificates
SSL certificates employ the SSL protocol to establish encrypted connections. They are commonly used to protect sensitive data such as login credentials, credit card information and personal details.

TLS certificates
TLS certificates are a type of SSL certificate, but they use the newer, more secure TLS protocol. Modern web browsers and servers now use TLS by default, 
making it the current industry standard for secure communication.

SSL and TLS protocols
The SSL and TLS protocols involve a series of steps to establish a secure connection between a client (usually a web browser) and a server. The process, known as an "SSL/TLS handshake," 
allows parties to authenticate each other and agree on encryption algorithms for the session.


Types of secure certificates
There are several types of secure certificates, each offering varying levels of validation and assurance to users:

Domain Validation (DV): DV certificates are the most basic type of secure certificate. They only check whether the requester has control over the domain for which the certificate was issued. 
This type of certificate is suitable for small websites and blogs where the main concern is data encryption.

Organization Validation (OV): OV certificates provide a higher level of validation. In addition to domain ownership, 
they also require verification of the organization's legal existence and physical location. OV certificates are typically used by companies and e-commerce sites that need to establish trust with their users.

Extended Validation (EV): EV certificates offer the highest level of validation and trust. They require a more rigorous verification process, 
which includes verifying the legal, operational and physical existence of the organization. Websites with EV certificates display a green address bar or padlock with the organization's name, 
providing a visible indication of security to users.

Obtaining a certificate
To obtain a secure certificate, you will need to choose a certificate authority (CA) and request the type of certificate that best meets your needs. 
The CA will then verify your information and issue the certificate, which can typically be done within a few hours or a few days, depending on the level of validation required.

Installing a certificate
Once you have obtained a certificate, you will need to install it on your web server. This process varies depending on the server software you are using, but generally 
involves configuring the server to use the certificate and its associated private key for secure communication.

Renewal and maintenance of secure certificates
Secure certificates have a limited lifespan, typically one to three years. When a certificate approaches its expiration date, it is essential to renew it to maintain a secure connection with your users. 
Failure to do so could result in warnings or security errors, which could harm your site's credibility and user experience.


------------  signed URLs 

If you've ever subscribed to something like a streaming service, a game pass, ebooks, or even webinars or online courses, then you've already experienced the convenience of accessing premium content with signed URLs
Signed URLs ensure that only authorized users can access certain resources, such as files or APIs, requiring users to have a valid signature before accessing the resource. 

the resource owner, like a streaming service provider, creates a key to sign the URLs. Then, the resource owner creates a signed URL by combining a few essential elements
including the resources URL, the secret key, and optional parameters like an expiration time or access level.

 Signed URLs can be used to securely share files with specific users, like confidential documents, images and videos.
This is especially important in industries like healthcare and finance, where sensitive data must be securely shared. 
APIs can be protected using signed URLs to ensure that only authorized users or applications can access specific endpoints or resources. 
This is crucial for maintaining the security of APIs and preventing unauthorized access to sensitive data.
Signed URLs can also be used to grant temporary access to resources for thirdparty services such as file conversion or analysis tools.
This enables secure collaboration with external partners while maintaining control over sensitive data. 

HMAC is a widely used algorithm for generating a unique signature based on a secret key and a message, which is, in this case, the URL. 
It provides a way to verify the data's integrity and the sender's authenticity. Then there's JSON Web Token, or JWT for short. 
JWT is a secure and compact way to share information between two parties over the Web. This information is in a special format called JSON, and it's safely signed digitally. 
In Web development, cookies are used to remember things about you, like your preferences and whether you've already signed in. So a JWT cookie is a special kind of cookie that carries a JWT. 
This is how it works, when you log into a website, the server creates a JWT with your information and puts it in a cookie. 
This cookie is sent back and forth between your browser and server, letting you stay logged in so you don't need to enter your password again. 
Finally, public key cryptography, or asymmetric cryptography as you've come to know it, can be used to generate signed URLs by using a private key to sign the URL and a public key to verify the signature. 
This approach provides an additional layer of security, as the private key is not shared with the end user or the server validating the signature. 


--------- configure server certificates

steps to enable server certificates and Secure Socket Layer (SSL) connectivity for sites and connections.


Step 1: Configuring and activating server certificates
To ensure secure communication and confirm the authenticity of your website, it is essential to configure and enable server certificates. See below how to do this:

Obtain a certificate from a certification authority (CA): To secure your website, you will need to obtain a digital certificate from a trusted CA. 
These certificates validate your website's identity and enable encrypted communication between your server and users' browsers. Top CAs include DigiCert, GlobalSign, and Let's Encrypt.

Install the certificate on your server: After receiving the certificate from the CA, install it on your server. The installation process varies depending on your web server 
(for example, Apache, Nginx, or Microsoft IIS). Follow your server's documentation for specific instructions on installing the certificate.

Configure the server to use the certificate: Once the certificate is installed, configure the server to use it for secure connections. 
Typically, this involves modifying the server configuration file to specify the location of the certificate and private key files.


Step 2: Use third-party certificates to enable SSL
Third-party certificates play a key role in enabling SSL for your website. This section provides an overview of the process of generating a Certificate Signing Request (CSR) and obtaining a third-party certificate.

Generate a CSR: The CSR contains information about your website and your organization that the CA will use to create your SSL certificate.
To generate a CSR, use a tool specific to your server software (for example, OpenSSL for Apache and Nginx or IIS Manager for Microsoft IIS). The CSR will include your domain name, organization name, and location.

Send CSR to CA: After generating the CSR, send it to your chosen CA. It will use the CSR information to create your SSL certificate. 
You may be required to verify domain ownership and organization details during this process.

Install the SSL certificate: After the CA issues the SSL certificate, install it on your server.


Step 3: Enabling SSL Connectivity for Your Website
With the SSL certificate installed and configured, you can now activate SSL connectivity for your website. This involves redirecting HTTP traffic to HTTPS (Hypertext Transport Protocol Secure), 
the secure version of your website.

Update the server configuration: To enable SSL connectivity, update the server configuration file to listen for HTTPS traffic on port 443 (the default SSL port). 
Also, make sure your server is configured to use the SSL certificate and private key files.

Redirect HTTP traffic to HTTPS: Configure your server to automatically redirect HTTP traffic to HTTPS, ensuring that all connections to your website are secure.
Typically this is done using rewrite rules in the server configuration file.


Step 4: Apply SSL to all connections
To maximize security, enforce SSL for all connections and specify the required encryption length between clients and the website.

Use Strict Transport Security (HSTS): Implement HTTP Strict Transport Security (HSTS) to tell browsers that your site should only be accessed using HTTPS. 
This reduces the risk of man-in-the-middle attacks and ensures that all connections are secure. Add the HSTS header to the server configuration file to apply HSTS.

Set the required encryption length: Encryption strength is measured in bits, with longer bit lengths offering stronger encryption. 
To set the required encryption length for your website, configure the server to use only strong encryption algorithms and key sizes. 
For example, opt for TLS 1.2 or TLS 1.3 with a minimum key length of 2048 bits for RSA or 256 bits for Elliptic Curve Cryptography (ECC).

Disable weak ciphers and protocols: To ensure maximum security, disable weak ciphers and outdated protocols in your server configuration. 
For example, disable SSL 2.0, SSL 3.0, and TLS 1.0 as they have known vulnerabilities. Additionally, disable weak cipher suites such as RC4 (Rivest Cipher 4), 
MD5 (Message-digest algorithm 5), and 3DES (Triple Data Encryption Standard).

Use secure cookies: Configure your server to use secure cookies transmitted only over HTTPS connections. This prevents confidential information contained in cookies from being intercepted during transit. 
To do this, add the Secure attribute to your website's cookies.

Check your SSL configuration: After applying SSL to all connections and setting the required encryption length, it is essential to check your SSL configuration. Use online tools, 
such as SSL Labs' SSL Server Test, to check your server's security settings and identify potential vulnerabilities.


https://learn.microsoft.com/en-us/azure/app-service/configure-ssl-certificate?tabs=apex
https://learn.microsoft.com/en-us/troubleshoot/developer/webapps/iis/www-administration-management/enable-ssl-all-customers


============== authorization and authentication   https://learn.microsoft.com/en-us/entra/identity-platform/authentication-vs-authorization

 The challenge of efficiently managing network access for a variety of users is a struggle for organizations of all sizes. 
Centralized authentication and authorization systems are integral to this task. Across multiple machines, servers, mobile users, and data centers, they provide an efficient solution for managing network access. 
Such a system consolidates access control, simplifies management, and enhances control. By having a single point of authentication,
organizations can enforce consistent access policies across various networks and services. This reduces the administrative workload associated with managing numerous access protocols 
and bolsters security by minimizing the potential for access violations and inconsistencies. 
Moreover, centralized authentication and authorization systems facilitate single sign on or SSO capabilities, a feature that significantly improves the user experience. 

This is not just for convenience, it also improves security. By reducing the number of times users must enter their credentials, the likelihood of phishing attacks, password theft, and other security breaches decreases.

Kerberos Distribution Center (KDC)
The Kerberos Distribution Center (KDC) is a common authentication system employed in computer networks. It operates based on the Kerberos protocol, which is widely used to authenticate users and provide secure access to network resources.

KDC components and steps
Kerberos is a network authentication protocol that uses secret-key cryptography to authenticate client-server applications.

See the steps involved below:

Authentication Service (AS) Exchange: The client requests an initial ticket from the Authentication Server (AS) component of the KDC. 
This request contains the customer ID and the ID of the service for which they want a ticket, usually a TGS (Ticket-Granting Service). 
At this point, the customer doesn't have any tickets, so this request is in plain text or sent with a previously shared secret key.

The customer receives the ticket grant ticket (TGT): The AS verifies the customer's credentials (in a typical configuration this might be checking a password).
If the customer is known and has access to grant, the AS creates a Ticket Grant Ticket (TGT). This TGT contains the customer ID, ticket validity period, and customer/TGS session key.
This TGT is encrypted using the TGS secret key. The AS also sends a copy of the client/TGS session key to the client, encrypted with the client's secret key.
The client describes the session key and keeps it for future communication.

Ticket Granting Service (TGS) Switch: When the client needs to communicate with another service, it sends a request to the Ticket Granting Service (TGS), including the TGT (which is still encrypted with the 
TGS secret key) , the ID of the service you want to access, and an authenticator, which contains the client ID and a timestamp, encrypted using the client/TGS session key.

The client receives the service ticket: The TGS decrypts the TGT and authenticator, verifies the information and, if everything is correct, creates a service ticket. This ticket contains the client ID, 
validity period, and a client/service session key encrypted using the service secret key. The TGS sends this service ticket to the client, along with a copy of the client/service session key encrypted with 
the client/TGS session key.

Client-server authentication: The client now has the service ticket and the client/service session key. To access the service, the client sends the service ticket (still encrypted with the service secret key) 
and a new authenticator (encrypted with the client/service session key) to the service. The service decrypts the ticket, extracts the session key from the client/service, and uses this key to decrypt the authenticator.
If all the information matches, the service sends back the confirmation and the client is authenticated to use the service.

A centralized authentication and authorization system can enhance security, improve efficiency, ensure consistency, and allow for better scalability.

Main authentication and authorization protocols
Several protocols play important roles in authentication and authorization. They set the standards for data exchange and help maintain the integrity and confidentiality of data during transmission.

RADIUS
To authenticate dial-in users and grant them access to the required system or service, remote access servers can communicate with a central server using the 
client-server protocol and software known as Remote Authentication Dial-In User Service (RADIUS).

RADIUS allows a company to keep track of user profiles in a shared database that all distant servers can access. Better security is provided by a central database, 
allowing an enterprise to create a policy that can be applied across a single managed network point.

SAML (Security Assertion Markup Language)
SAML (Security Assertion Markup Language) is a standard for exchanging authentication and authorization data between parties. SAML is often used to implement Single Sign-On (SSO). 
It is mainly used in scenarios to allow users to log in once and gain access to multiple systems, applications or services without having to log in again.

OAuth (Open Authorization)
OAuth (Open Authorization) is an open standard for token-based authentication and authorization on the Internet. It allows third-party services to exchange your information without the user having 
to provide their password.
It is commonly used as a way for Internet users to give websites or applications access to their information on other websites, but without providing passwords.

In the context of OAuth, a resource owner refers to an entity that can grant access to a protected resource. Typically, the resource owner is the end user. For example, 
if a third-party application wants to access a user's data stored on a service like Google or Facebook, the user (the resource owner) must grant the third-party application permission to access that data.

OpenID Connect
This is a thin identity layer built on top of the OAuth 2.0 protocol. It allows clients to verify the identity of the end user based on authentication performed by an authorization server 
and obtain basic profile information about the end use


Choosing the right authentication and authorization system
Choosing the right system mainly depends on your specific requirements. If you need more authorization, OAuth may be the best option. If the issue is authentication, 
OpenID Connect may be a better fit. For single sign-on scenarios, SAML may be the most suitable protocol.


https://learn.microsoft.com/en-us/azure/app-service/overview-authentication-authorization



--------Transmission threats. 

some of these techniques including eavesdropping, sniffing, and MiTM.


One possible way is by the attacker firstly, compromising the connection. This includes connections like public Wi-Fi or Ethernet networks, or the attacker accessing something physical like a switch or router, 
then the attacker pretends to be an access point for the Wi-Fi or router or an Ethernet switch. 
This establishes the connection making you believe that you are communicating with the other party directly. 

MiTM attacks can be avoided by employing strong encryption techniques and digital certificates to sign conversations. 
Furthermore, if you need to access critical services, you should avoid connecting to public untrusted networks.


Another technique attackers use is something called SSL stripping. This technique downgrades a secure HTTPS connection to the less secure HTTP connection. 
This method effectively bypasses the encryption provided by SSL and TLS, thus allowing the attacker to intercept and read your sensitive data that has been transmitted.
The victim attempts to connect to a secure website using HTTPS. The attacker positioned between the victim and the server intercepts the request and establishes a HTTPS connection 
with the targeted websites on the victim's behalf. The attacker then sends the requested content to the victim over an unencrypted HTTP connection, while maintaining the HTTPS connection with the targeted website. 
The victim, unaware of the downgrade to HTTP, sends sensitive information to the attacker in plain text.
The attacker can now read, modify, or steal the data before forwarding it to the intended recipient of the original HTTPS connection.

A replay attack is another approach used by attackers. A replay attack involves an attacker maliciously capturing and retransmitting data. 
Even when the data is encrypted, retransmitting the encrypted packets can enable an attacker to carry out an MiTM attack or authenticate themselves as a valid user.
When the attacker captures an encrypted message that can retransmit it and the receiver noticing valid ciphertext decrypts it. 
The easiest way to prevent replay attacks is to use one-time passwords or OTPs

Wireshark   https://www.wireshark.org/
The first is Wireshark, an open source tool that allows you to analyze the network on a microscopic level. 
Commonly known as a network protocol analyzer, Wireshark allows you to interactively capture and browse traffic running on a computer network. 
It can run on multiple platforms including Windows, MacOS and Linux.

Cain & Abel
It helps users to recover various types of passwords
Detecting network traffic,
Crack encrypted passwords,
VoIP conversation recording and much more.

Ettercap    https://www.ettercap-project.org/
Next up is Ettercap, which is a comprehensive tool for man-in-the-middle attacks on a LAN (Local Area Network). 
It can intercept traffic on a network segment, capture passwords, and perform active spying on common protocols.

TCPDump  https://www.tcpdump.org/
Another tool is TCPDump, a powerful command-line packet analyzer used to view TCP/IP packets traveling across the network. It's like a security camera for your network! 
You can observe all data entering and leaving your network and record it for later analysis. This can also be very useful for troubleshooting network issues or investigating suspicious network activity.

TCPDump works by capturing data packets passing through a network. It then decodes and prints the packets into a readable format. This allows you to see exactly what data is being sent and received on your network. 
It includes a wide range of options that allow you to filter and view packet data in a variety of ways. 
For example, you can filter packets based on IP address, protocol type, packet size, and many other factors, making it a highly flexible tool for network analysis and troubleshooting.

Other data transmission interception tools

TCPflow is a command-line utility that captures data transmitted as part of TCP connections and stores the data conveniently for protocol analysis and debugging.

Snort is an open source intrusion prevention system capable of analyzing real-time traffic and logging packets. It is known for its flexibility and protocol analysis capabilities.
https://www.snort.org/

Suricata is another open-source network threat detection engine capable of detecting intrusions in real-time, monitoring network security, and capturing offline packets.

Dsniff is a set of tools used for network auditing and penetration testing. Dsniff can capture passwords, protocol information, and more across a network.

Tshark is a network protocol analyzer that allows you to capture packet data from an active network or read packets from a previously saved capture file. It is the terminal-based version of Wireshark.


------ VPN

 how do VPNs work? Well, a VPN starts by creating a secure encrypted connection between your device and a remote server operated by the VPN service.
This secure connection is often referred to as a VPN tunnel, all internet traffic that passes through this tunnel is encrypted and therefore secure from interception. 
So when you activate your VPN using VPN software, your device connects to the VPN server, this server could be located anywhere in the world. 
Secure protocols such as OpenVPN, L2TP or IPSec, SSTP, and lastly, IKEv2 are used to create the connection.
Your VPN provider chooses a protocol based on your specific needs, including your device compatibility speed and level of security. 
Then, once your connection is established, the VPN encrypts your data, as you know, encryption is the process of converting data into a code to prevent unauthorized access. 
VPNs have strong encryption protocols like AES-256 to encrypt the data before it leaves your device, making your data unreadable to anyone who might want to intercept it. 
After encryption, the data is transmitted through the VPN tunnel to the VPN server, so even if a hacker intercepts your data, since it's encrypted, they won't be able to decrypt it due to the encryption.

This not only keeps your data secure, but also helps protect your online identity and allows you to bypass geographic restrictions on content. 

what method does your device use to connect to the VPN server? These methods are known as the VPN protocol, let's explore them now. 
First is OpenVPN protocol, which is highly secure and versatile, it's compatible with various encryption algorithms and is widely regarded as the industry standard. 
Next is the L2TP or IPSec, which is actually two protocols used together, L2TP or layer to tunnel protocol creates the tunnel and IPSec, or internet protocol security handles the encryption. 
L2TP is considered secure but slower than OpenVPN due to its double encapsulation, you also have a point-to-point tunneling protocol, or PPTP, which is one of the oldest protocols. 
While it's fast and easy to set up, it's not a secure option as hackers can manipulate it quite easily. 
Lastly, internet key exchange version 2or IKEv2, is a fast and secure protocol that is excellent at re-establishing your connection if it gets interrupted. 

how do you choose the right VPN for you?

 firstly, consider the security protocols that the VPN software supports. Next, find out if they keep a log of your browsing data, explore how many server locations they offer.
You should also make yourself aware of what bandwidth comes with the software, is the VPN software compatible with your device's operating system? 
And lastly, before buying a VPN subscription, find out how many devices you can connect to a single account


--------- Threats to IoT

Weak authentication mechanisms
Outdated firmware
IoT botnets and threats to data transmission
Insufficient privacy protections
Lack of standardization
Insecure network services
Insecure ecosystem interfaces
Poor physical security


Best practices to avoid IoT risks and threats

Protect devices
Implement strong authentication
Use encryption
Network segmentation
Regular audits and monitoring
User awareness and education
Buy from trusted manufacturers
Disable unnecessary features


---------- firewall optimazation

 firewall optimization strategy that includes rule management, strategic rule prioritization, regular audits, and continuous monitoring and logging for better and efficient traffic management. 

it's important to remove redundancies and outdated rules. A firewall operates by executing a set of rules that define the traffic to be allowed or blocked. Over time, these rules can accumulate, 
leading to redundancies, conflicts, or even outdated rules that no longer serve a purpose. For example, if the firewall rule set contains multiple rules for the same traffic type, it could lead 
to unnecessary processing and potential security vulnerabilities. Also, if a rule corresponds to an obsolete service, it can become a gateway for threats.
Therefore, it's critical to regularly review and remove these redundant and outdated rules to improve the efficiency and security of the firewall.

Effective audits can identify configuration errors, obsolete rules, and potential security risks enhancing the performance and reliability of the firewall. 

Configuring a firewall involves several steps, such as selecting the right type of firewall, defining security rules and policies, implementing Network Address Translation (NAT), 
and regularly maintaining and updating the firewall software.

https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/windows-firewall/create-an-inbound-port-rule
https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/windows-firewall/create-an-outbound-port-rule
https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/windows-firewall/windows-firewall-with-advanced-security
https://pureinfotech.com/allow-apps-firewall-windows-11/
https://learn.microsoft.com/en-us/windows/security/operating-system-security/network-security/windows-firewall/best-practices-configuring


---types of firewall

Packet filtering firewalls, the most basic type, inspect packets and make decisions based on source and destination addresses.

A circuit-level gateway works at the session layer of the OSI model, monitoring TCP handshakes on the network to determine whether a requested session is legitimate.

A stateful inspection firewall, a significant improvement over the packet filtering type, monitors active connections and uses state information to determine the legitimacy of traffic packets. 
it is smarter and offers a higher level of security.

Proxy firewalls provide more security by filtering messages at the application layer.

NGFWs offer the most comprehensive security, combining traditional firewall capabilities with advanced features such as intrusion prevention systems (IPS) and application recognition.


--------- IDPS

An IDPS is a software or hardware based security solution that monitors network traffic and system activities to identify potential security breaches.
Its primary goal is to detect and respond to intrusions whether they are attempted attacks, malware infections, unauthorized access or any other malicious 
activities that may compromise the integrity, confidentiality or availability of a network or system. 
When it detects something unusual or suspicious happening within the network it immediately raises an alarm and sends alerts to designated individuals or security personnel. 

These alerts provide crucial information about the nature of the intrusion, enabling swift response and mitigation measures to minimize potential damage and protect the organization's assets

 different types of detection. Signature based detection compares incoming data against a database of known attack signatures. 
Anomaly based detection establishes a baseline of normal behavior and raises alerts when deviations occur.
Finally, behavioral analysis monitors users and system behavior, detecting suspicious activities that may indicate an intrusion attempt. 

false positives and negatives IDPS systems may generate false alerts, flagging legitimate activities as threats known as false positives or fail to detect actual intrusions known as false negatives.
Keeping the right balance between accuracy and minimizing false alerts is a challenge. 


-=-------------endpoints and endpoint security

An endpoint refers to an individual device such as a laptop, desktop, smartphone, tablet, server, or any networked device that serves as an entry point to a network.

Endpoint security best practices
To increase the effectiveness of endpoint security measures, organizations must follow some best practices.

Regularly updating and patching endpoints with the latest security fixes helps resolve known vulnerabilities and bugs.

Implementing strong password policies with multi-factor authentication adds an extra layer of protection.

Educating and training employees about these threats helps them identify risks and respond to them first.

Network segmentation helps isolate endpoints and sensitive data, minimizing the risk of cyberattacks and data breaches.

Endpoint encryption protects sensitive and confidential data.

Regular data backups help restore working files in case of data loss.

Regular monitoring and analysis of endpoints using EDR (Endpoint Detection and Response) solutions allows for real-time threat detection.

Following the principle of least privilege reduces the risk of unauthorized access using these endpoints.

And finally, conducting regular audits ensures that endpoints follow compliance rules and regulations.


--------- Endpoint security technologies
Endpoint security solutions typically consist of several core components that work together to protect endpoints from cyber threats. Let's explore some common components found in endpoint security solutions.

Antivirus and antimalware: Detects and prevents malware infections.

Firewall: Monitors and controls network traffic to prevent unauthorized access.

Intrusion Detection and Prevention System (IDPS): Identifies and alerts you to potential security breaches.

Data Loss Prevention (DLP): Protects sensitive data from unauthorized access or leakage.

Endpoint encryption: Ensures that data stored on endpoints remains secure even if the device is lost, stolen or compromised. It encrypts data using strong algorithms, 
making it unreadable without the appropriate decryption key.

Patch management: Implements security patches and updates to keep endpoints up to date.

Device and application control: Manages access to and use of peripheral devices and applications.

Behavioral analytics: Monitors user and endpoint behavior using machine learning and artificial intelligence algorithms to detect anomalies.

Endpoint Detection and Response (EDR): Provides advanced threat detection, real-time monitoring, and incident response capabilities.


Microsoft endpoint security solutions
Microsoft offers a comprehensive suite of endpoint security solutions designed to protect individuals and organizations against evolving cyber threats. Let's explore some of them:

Microsoft Defender Antivirus: Formerly known as Windows Defender, this integrated antivirus solution provides real-time protection against malware, viruses, and other malicious software. 
It offers advanced threat detection and remediation capabilities, including cloud-based machine learning and behavior-based analytics.

Microsoft Defender Firewall: This network-grade firewall protects endpoints from unauthorized network access and inbound/outbound traffic. 
It monitors and controls network communications to prevent intrusions and blocks potentially harmful connections.

Microsoft Intune: It is a cloud-based endpoint management solution that allows organizations to manage and secure endpoints across different platforms, including Windows, macOS, iOS, and Android. 
It offers features such as device management, application control, and data protection to enforce security policies and ensure compliance.

Microsoft Azure Sentinel: This cloud-native security information and event management (SIEM) solution provides intelligent threat detection and response capabilities. 
It aggregates and analyzes endpoint and network data, helping organizations detect and respond to advanced threats across their infrastructure.

Microsoft Secure Score: Secure Score provides organizations with a comprehensive assessment of their endpoint security posture. It offers practical recommendations and guidance to improve security. 
The Microsoft Secure Score is a measure of an organization's security posture, with a higher number indicating more recommended actions to take.

https://learn.microsoft.com/en-us/windows/deployment/update/how-windows-update-works
https://www.microsoft.com/en-gb/industry/blog/government/2020/06/26/how-to-have-secure-remote-working-with-a-byod-policy/
https://www.n-able.com/blog/the-top-7-risks-of-bring-your-own-device-msps-should-remember


----------- security compliance

 using risk management strategies to spot and treat risks before they cause major damage. 
And maintain compliance to reduce the chance of operational disruptions, financial penalties, and damage to the business's reputation

Security compliance refers to the process of adhering to a set of specific laws, regulations, and guidelines designed to protect data and information systems.
It's a comprehensive approach that encompasses safeguarding data, controlling who has access to it, and managing how it's shared and stored. 
It's a way of ensuring that data isn't just stored, but stored responsibly and securely. 

Compliance, on the other hand, is about adhering strictly to a specific set of rules. These could be laws and regulations, standards or guidelines pertinent to your business. 
For example, in Sam's case, risk management involves identifying and reducing risks associated with customer data, financial records, and employee information. 
While compliance means following laws, standards, and regulations on data privacy and financial reporting. 

 how risk management takes form. Risk management generally involves four phases, identification, assessment, response, and monitoring and reporting. 
The process begins with identifying potential risks in all key areas using information from various sources such as interviews, vulnerability scans, and incident reports. 
Then, in the assessment phase, each risk is evaluated based on impact, likelihood, and control deficiency. Impact refers to potential damage to the company. 
Likelihood measures the probability of the risk occurring, and control deficiency assesses the effectiveness of implemented mitigation strategies. 
The combination of these metrics provides a risk score, which is presented to key stakeholders for verification.


-----------  your permission to use cookies when you visit a website

they are a direct result of the GDPR, a regulation that's all about protecting your online privacy.
GDPR keeps your privacy intact while still letting you enjoy the wonders of the Internet.

Browser cookies or a HTTP cookies are small, bite-sized pieces of data that websites store on your computer. Their main function is to remember you and your preferences for a specific website. 
They are the reason you don't have to log in every time you visit your favorite site. Why you don't lose items in your online shopping cart, even if you accidentally close the browser. 
Plus these cookies can even help show you ads that match your browsing habits.

The GDPR has completely transformed privacy laws and put the power back into the hands of the individuals like you. 
But how does it relate to those seemingly innocent browser cookies you encounter on a daily basis? 
Simply put, the GDPR recognizes cookies as personal data if they have the potential to identify you either directly or indirectly. 
This means that companies have a responsibility to obtain explicit and informed consent before they store access these cookies. 
The GDPR requires companies to be upfront about why they're collecting your data, how it will be used, and whether it will be shared with third parties. It's all about transparency and the law that mandates it.
the site uses cookies and provides options for you to accept, reject, or customize the level of cookies you're comfortable with. It's no longer about merely informing you that cookies are being used.

PCI-DSS (Payment Card Industry Data Security Standard) is a set of security standards created to ensure that all companies that accept, process, store or transmit credit card information maintain a secure environment.

https://learn.microsoft.com/en-us/training/modules/describe-security-concepts-methodologies/6-describe-compliance-concepts?ns-enrollment-type=learningpath&ns-enrollment-id=learn.wwl.describe-concepts-of-security-compliance-identity
https://learn.microsoft.com/en-us/training/paths/describe-concepts-of-security-compliance-identity/
https://learn.microsoft.com/en-us/microsoft-365/lti/browser-cookies?view=o365-worldwide&tabs=edge
https://learn.microsoft.com/en-us/entra/identity/authentication/concept-authentication-web-browser-cookies


-------------- manage identity

By implementing best practices such as Active Directory for authentication, rigorous access control for authorization, and identity federation for cross domain access. 
You and your organization can build a resilient defense against potential cyber threats.

let's say Ashley needs to access data from Sam scoop server. In this case, Ashley's identity is represented by a username and password, while the server's identity is represented by an IP address. 
This is where identity management comes into accurately defined verifying govern these identities, to ensure secure interactions between them. 
Identity management isn't merely about knowing who or what the entities are. It's also about ensuring the appropriate entities have the right level of access to the right resources at the right time.
But it doesn't stop there. Identity management encompasses the entire life cycle of digital identities within a system. It starts with creating an identity when a new user or a system components is added to the network. 
Then this involves maintaining and updating the identity. Adjusting access rights as required, or revoking them when they're no longer needed. Now what about the tools that facilitate this process? 
Active Directory is a Microsoft service that is a pivotal component in identity management. 

It serves as a virtual directory for your network, organizing and controlling data access and managing user interactions throughout the system.
Think of it like a digital phone book for your network. Storing directory data in a structured way and offering services to manage resources effectively.

using your Google Account to sign up for an online streaming service. This is federated identity at work. It enables you to log in at one location and seamlessly switch to another without the need to login again. 
Identity federation signifies a set of agreements, protocols, and technologies enabling you to use a single digital identity to access resources across multiple security domains from different enterprises.


--------- Active Directory (AD) and access control
https://learn.microsoft.com/en-us/training/modules/introduction-to-ad-ds/2-define-ad-ds
https://learn.microsoft.com/en-us/entra/identity/enterprise-apps/what-is-single-sign-on

AD is a directory service developed by Microsoft for Windows domain networks. It is included with most Windows Server operating systems and provides several network services, including LDAP, 
Kerberos-based authentication, and DNS. Additionally, AD centralizes the administration and security of an enterprise IT environment.

Access control is at the core of AD's functionality, managing who can and cannot access specific resources on a network. This management is done in two parts: authentication and authorization. 
Authentication verifies the identity of the user trying to gain access, while authorization determines what authenticated users can and cannot do.

AD employs a mechanism known as access control lists (ACLs) to implement authorization. Each object in an AD (users, computers, printers, network shares, etc.) 
has an ACL attached, which defines who has access to the object and what operations can be performed.


Identity Federation and Active Directory Federation Services (AD FS)
It's not uncommon for people to access resources outside of their home domain. Think about the times you used a single account, like your Microsoft account or a social media profile, to sign in to different websites.

Identity federation allows your digital identity, stored in one system (the home domain), to be used by other systems (partner domains), even if those systems use different authentication methods.
This facilitates single sign-on (SSO), allowing you to authenticate once and gain access to multiple systems.

SSO is an innovative authentication scheme that allows you to log into multiple yet distinct software systems using a single set of credentials. 


 To understand how Active Directory works, it's essential to first familiarize yourself with its key components, including domains, domain controllers, organizational units and trust relationships.
Domains are logical containers within Active Directory that group and organize resources. Each domain has its own unique domain name and maintains a separate security boundary.
Domain controllers are servers that run the Active Directory domain services role. They authenticate users, enforce security policies, and replicate Directory across the network. 
Organizational units are containers within Domains that help organize and manage resources based on administrative needs. They provide a way to delegate administrative authority and apply Group Policy settings. 
Trust relationships establish connections between domains to enable secure resource sharing and authentication across different parts of the network.

In addition to configuration management, Active Directory plays a crucial role in managing user identities within an organization, providing features for creating, modifying and disabling user accounts,
as well as managing authentication and authorization.

----Group Policy.
This integral aspect of Microsoft's Active Directory service empowers administrators with a versatile toolset for managing user and computer environments across an enterprise network. 
As you may recall, Group Policy allows for the centralized management and control of operating systems, applications and user settings in an Active Directory environment.

the combination of Group Policy settings in Active Directory empowers administrators to efficiently manage user identities, enforce security policies, and control access to network resources within an organization. 

With Group Policies, administrators can:

establish password rules,
manage user permissions,
implement software and
control system updates.



------------- defense in depth   https://learn.microsoft.com/en-us/training/modules/azure-well-architected-security/2-defense-in-depth

There is no one-size-fits-all solution to the myriad security threats organizations and individuals face. Instead of multifaceted layered approach is needed to boost the defense against various attack vectors. 

Defense in depth is a strategy that employs a series of protective mechanisms to slow the advance of an attack aimed at acquiring unauthorized access to information. 
Each layer adds a protective barrier, ensuring that subsequent layers are ready to mitigate the impact and prevent further intrusion even if one is breached.
Microsoft employs this layered security approach in its physical datacenters and Azure services.
The primary objective is to protect information and prevent unauthorized access. The confidentiality, integrity, and availability principles, often called the CIA triad


confidentiality is about ensuring the access to information is restricted to authorized individuals. This principle is upheld by protecting user passwords, encrypting sensitive data, and securing email content. 
Integrity involves preventing unauthorized information changes, whether at rest or in transit. Techniques like one-way hashing algorithms safeguard data integrity, which generates 
a unique fingerprint of the data ensuring it hasn't been tampered with during transmission. 
Availability, the third pillar of the CIA triad ensures that services and resources are accessible to authorized users whenever needed. 
Mechanisms such as redundancy, failover protocol, and geographical dispersal of resources are employed to maintain continuous service availability and minimize single points of failure.

The first layer focuses on protecting data, which is often the primary target for attackers.
The second layer focuses on securing applications as they serve as crucial gateways to data.
The third layer is compute. This layer focuses on the security of virtual machines and endpoint devices.
the network layer that focuses on controlling and limiting communication to prevent unauthorized access and lateral movements within the network. 
the perimeter. This layer is about shielding your network from large-scale attacks from the outside. Implementing distributed denial-of-service protection and perimeter firewall is can help identify, mitigate, and raise alerts for potential attacks.
the physical security brings the defense model full circle. This stage involves preventing unauthorized physical access to assets, which can bypass other security layers if not appropriately safeguarded. 


------------- Zero Trust model  - the saying, never trust, always verify.    https://learn.microsoft.com/en-us/security/zero-trust/zero-trust-overview

A new approach to data security that goes beyond products and services built on the principles of verify explicitly, use least privilege access and assume breach.

The first-principle verify explicitly emphasizes the importance of continuous authentication and authorization. Based on all available data points. 
It is not good enough to know who is trying to access your network. You also need to know their device, their location, and more. 
The second principle of least privilege access means limiting user access with in time and enough access policies. 
These policies restrict access to what's needed for a specific task, reducing the potential impact of a breach. 
The final principle, assume breach involves taking a defensive stance by minimizing the area of impact, segmenting access, verifying end-to-end encryption,
and using analytics to drive threat detection and improved defenses. 

the six critical elements that must be secured to ensure a robust zero-trust model. 
Identities, devices, applications, data, infrastructure, and networks.


The importance of monitoring in security operations
One of the main elements that highlight the importance of monitoring is its proactive function. Instead of reacting to threats after the incident, security monitoring empowers SOCs to anticipate and 
neutralize threats in advance. 
It enables the identification of subtle indicators of compromise that could initiate an attack through continuous surveillance of network activities and system behaviors.

Security Monitoring Tools
The effectiveness of security monitoring largely depends on the tools used. Tools such as IDS (Intrusion Detection Systems), SIEM (Security Information and Event Management),
and log management solutions form the crux of any effective monitoring strategy.


---------- Azure AD -> Entra ID   https://learn.microsoft.com/en-us/entra/fundamentals/whatis

Microsoft is renaming Azure Active Directory to Microsoft Entra ID.
 Active Directory is a service tasked with managing all of the resources on a network. 

establishing a connection between the on-premises AD and Azure Active Directory. This can be done using Azure AD Connect, which synchronizes user accounts and passwords from an on-premises AD to Azure AD.
Azure AD Connect works by installing software on the on-premises AD server.
migrate the user accounts and groups from AD to AAD. Azure AD Connect tool. This tool allows administrators to select the users and groups that need to be migrated and transfer them to the AAD. And ensures 
that all the necessary attributes and properties are transferred correctly.
migrating users and groups is the Active Directory Migration Tool, ADMT. ADMT allows you to extract passwords, group memberships, and other attributes associated with users and groups, and duplicate them in the cloud. 
migrating any applications and services that are dependent on AD to AAD. This involves reconfiguring the applications and services to use AAD for authentication and authorization instead of AD.

Azure Active Directory or AAD, is a modern way of managing network resources and users.
It is much easier to incorporate a third-party SaaS into business operations

Companies that decide to keep both the AD while using the AAD as the primary source maintain a secure backup which acts as a fail-safe in the event of an unforeseen incident causing data loss. 

Before transitioning to AAD it is important to practice user account management by cleaning up existing accounts. 
An account cleanup includes removing inactive users, removing duplicates, and validating contact information, and reviewing account information. 

AAD Connect provides the additional functionality of password and device write-back. This means that any changes made to the AAD will be mirrored in the AD, 
ensuring efficacy in cases where it must act as a fail-safe solution

Another question that might come up for an organization is how to implement a virtual network or VN to communicate between the AD and the AAD. 
Here, the VN connects the AAD and the AD using a VPN gateway. This allows the organization to communicate between the two networks without compromising security. 
The VN can be configured with security groups and network specifications to appropriately control the flow of traffic between these resources. 

https://learn.microsoft.com/en-us/entra/identity/domain-services/tutorial-create-instance
https://learn.microsoft.com/en-us/entra/identity/hybrid/connect/whatis-azure-ad-connect
https://learn.microsoft.com/en-us/entra/fundamentals/how-subscriptions-associated-directory
https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/manage-resource-groups-portal
https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/ready/landing-zone/design-area/azure-billing-cloud-solution-provider


B2B direct connect supports direct connection between businesses. This enables external users to access your resources within their home instances and the organization to access theirs. 
B2B direct connect users aren't represented in your directory, but are visible from within and can be monitored. 

B2C allows the creation of an identity on the site separate from any existing social media account. However, access gain this way only enables interaction with a given application or service created. 


SAML
This is an XML-based protocol for communicating with identity providers.

OAuth is a technical standard for authorizing users. It is a protocol for passing authorization from one service to another without sharing the user's actual credentials such as username and password. 
With OAuth, a user can sign in to one platform and then be authorized to perform actions and view data on another platform.

https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview
https://learn.microsoft.com/en-us/entra/external-id/external-identities-overview
https://learn.microsoft.com/en-us/azure/active-directory-b2c/add-identity-provider#select-an-identity-provider
https://learn.microsoft.com/en-us/azure/role-based-access-control/scope-overview  
https://techcommunity.microsoft.com/t5/itops-talk-blog/what-s-the-difference-between-azure-roles-and-azure-ad-roles/ba-p/2363647
https://learn.microsoft.com/en-us/azure/bot-service/bot-builder-concept-authentication?view=azure-bot-service-4.0
https://learn.microsoft.com/en-us/entra/identity-platform/app-objects-and-service-principals?tabs=browser


